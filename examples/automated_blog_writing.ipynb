{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated article writing about your project with ChatGPT in fewer than 100 lines of code!\n",
        "\n",
        "This Jupyter Notebook showcases an efficient method to automate article writing for your project using ChatGPT and PyDoxTools in fewer than 100 lines of code. The script demonstrates the following key functionalities:\n",
        "\n",
        "- Indexing a directory containing files with PyDoxTools\n",
        "- Employing an agent for information retrieval within those files\n",
        "- Auto-generating a text based on a set objective\n",
        "\n",
        "You can execute this notebook or simply refer to our concise script, which encompasses these steps in less than 100 lines of code:\n",
        "\n",
        "https://github.com/Xyntopia/pydoxtools/blob/main/examples/automatic_project_writing.py\n",
        "\n",
        "\n",
        "or open this notebook in colab:\n",
        "\n",
        "https://colab.research.google.com/github/Xyntopia/pydoxtools/blob/main/examples/automated_blog_writing.ipynb\n",
        "\n",
        "## Costs\n",
        "\n",
        "ChatGPT is a paid service. Running this script once will cost you about 2-5 Cents. We are working on an implementation making use of ALpaca/GPT4all and similar models which can do the same for free, locally on your computer. Pydoxtools automatically caches all calls to ChatGPT. So subsequent runs usually turn out to be a little cheaper"
      ],
      "metadata": {
        "id": "D1ulBrzuWda2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### API key for ChatGPT\n",
        "\n",
        "Generate an openai API-key for chatgpt here:  https://platform.openai.com/account/api-keys. You need to register an account for this.\n",
        "\n",
        "!!! Important !!!  Do not share the API key with anybody. In order to be on a more safe side, save the API key in a file here in colab. This way you can share the notebook without sharing the API key.\n",
        "\n",
        "Execute the cell below to create the file. The notebook will later open this file to access the API key. When the colab runtime gets automatically deleted, this file will also be deleted.\n"
      ],
      "metadata": {
        "id": "TMjdeX-wRTIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!touch /content/openai_api_key"
      ],
      "metadata": {
        "id": "MFUWt9S3TFqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "then click this link: /content/openai_api_key and copy&paster your key into the file."
      ],
      "metadata": {
        "id": "aH2hf2liYUKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation\n",
        "\n",
        "After installation go to Runtime -> Restart runtime. In order to load the newly installed libraries into jupyter.\n"
      ],
      "metadata": {
        "id": "sGD2Nxt8JN4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U pydoxtools[etl,inference,all]==0.6.2"
      ],
      "metadata": {
        "id": "E6dYMNYvFsMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the key as an environment variable:\n",
        "import os\n",
        "# load the key\n",
        "with open('/content/openai_api_key') as f:\n",
        "  os.environ['OPENAI_API_KEY']=f.read()"
      ],
      "metadata": {
        "id": "U5y6M-UqT0EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we can initialize pydoxtools automatically loading our api key from the environment variable"
      ],
      "metadata": {
        "id": "KbkcG16YWR3u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqOo-swAFlai"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "import dask\n",
        "from chromadb.config import Settings\n",
        "\n",
        "import pydoxtools as pdx\n",
        "from pydoxtools import agent as ag\n",
        "from pydoxtools.settings import settings\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logging.getLogger(\"pydoxtools.document\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## configuration\n",
        "\n",
        "Set dask scheduler to \"synchronous\" so that we can see everything thats happening locally and turn on cacching for pydoxtools for faster repeated execution"
      ],
      "metadata": {
        "id": "4GkFQIXDICYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pydoxtools.DocumentBag uses a dask scheduler for parallel computing\n",
        "# in the background. For easier debugging, we set this to \"synchronous\"\n",
        "dask.config.set(scheduler='synchronous')\n",
        "# dask.config.set(scheduler='multiprocessing') # can als be used...\n",
        "\n",
        "settings.PDX_ENABLE_DISK_CACHE = True  # turn on caching for pydoxtools"
      ],
      "metadata": {
        "id": "O-PwVOwsHnDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download our project\n",
        "\n",
        "you could also mount a google drive here. or simply load a folder on your computer is you#re running this notebook locally on your computer."
      ],
      "metadata": {
        "id": "GiQ2p-cLcvyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content\n",
        "!git clone https://github.com/Xyntopia/pydoxtools.git"
      ],
      "metadata": {
        "id": "YB0Lh2uJIemO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index initialization\n",
        "\n",
        "Set our vectorstore settings. We are using chromadb here."
      ],
      "metadata": {
        "id": "u-kWx8q7IT_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Use chromadb as a vectorstore #####\n",
        "chroma_settings = Settings(\n",
        "    chroma_db_impl=\"duckdb+parquet\",\n",
        "    persist_directory=str(settings.PDX_CACHE_DIR_BASE / \"chromadb\"),\n",
        "    anonymized_telemetry=False\n",
        ")\n",
        "collection_name = \"blog_index\"\n",
        "\n",
        "# create our source of information. It creates a list of documents\n",
        "# in pydoxtools called \"pydoxtools.DocumentBag\" (which itself holds a list of pydoxtools.Document) and\n",
        "# here we choose to use pydoxtools itself as an information source!\n",
        "root_dir = \"/content/pydoxtools\"\n",
        "ds = pdx.DocumentBag(\n",
        "    source=root_dir,\n",
        "    exclude=[  # ignore some files which make the indexing rather inefficient\n",
        "        '.git/', '.idea/', '/node_modules', '/dist',\n",
        "        '/__pycache__/', '.pytest_cache/', '.chroma', '.svg', '.lock',\n",
        "        \"/site/\"\n",
        "    ],\n",
        "    forgiving_extracts=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "vUhM1QhAH7uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize agent, give it a writing objective and compute the index\n",
        "\n",
        "For pydoxtools as in this example his will take about 5-10 minutes. And we will load about 4000 text snippets into our vector index for the [pydoxtools](https://github.com/Xyntopia/pydoxtools) project.."
      ],
      "metadata": {
        "id": "aeKUMGR1J_CJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_result = []\n",
        "\n",
        "agent = ag.Agent(\n",
        "    vector_store=chroma_settings,\n",
        "    objective=\"Write a blog post, introducing a new library (which was developed by us, \"\n",
        "              \"the company 'Xyntopia') to \"\n",
        "              \"visitors of our corporate webpage, which might want to use the pydoxtools library but \"\n",
        "              \"have no idea about programming. Make sure, the text is about half a page long.\",\n",
        "    data_source=ds\n",
        ")\n",
        "agent.pre_compute_index()"
      ],
      "metadata": {
        "id": "Q0_Qak1aIROq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search for relevant Information"
      ],
      "metadata": {
        "id": "uNt1SdADQiUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First answer a basic question, to get the algorithm started more quickly..."
      ],
      "metadata": {
        "id": "9jRmKi6MQtdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# first, add a basic answer, to get the algorithm started a bit more quickly :) \n",
        "# we could gather this information from a user in a \"real app\"\n",
        "agent.add_question(question=\"Can you please provide the main topic of the project or some primary \"\n",
        "                            \"keywords related to the project, \"\n",
        "                            \"to help with identifying the relevant files in the directory?\",\n",
        "                    answer=\"python library, AI, pipelines\")\n"
      ],
      "metadata": {
        "id": "zLG6v7nLKF3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then search for more answers in our index"
      ],
      "metadata": {
        "id": "7be7qww_Q4q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first, gather some basic information...\n",
        "questions = agent.execute_task(\n",
        "  task=\"What additional information do you need to create a first, very short outline as a draft? \" \\\n",
        "        \"provide it as a ranked list of questions\", save_task=True)\n",
        "# we only use he first 5 questions to make it faster ;).\n",
        "agent.research_questions(questions[:5], allowed_documents=[\"text/markdown\"])\n"
      ],
      "metadata": {
        "id": "NUPcDZiEQ3iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now write the text..."
      ],
      "metadata": {
        "id": "JjqTJ_20RB6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt = agent.execute_task(task=\"Complete the overall objective, formulate the text \"\n",
        "                              \"based on answered questions and format it in markdown.\",\n",
        "                          context_size=20, max_tokens=1000, formatting=\"txt\")\n",
        "final_result.append(txt)  # add a first draft to the result\n",
        "\n",
        "critique = agent.execute_task(task=\"Given this text:\\n\\n```markdown\\n{txt}\\n```\"\n",
        "                                    \"\\n\\nlist 5 points of critique about the text\",\n",
        "                              context_size=0, max_tokens=1000)\n",
        "\n",
        "tasks = agent.execute_task(\n",
        "    task=\"Given this text:\\n\\n```markdown\\n{txt}\\n```\\n\\n\"\n",
        "          f\"and its critique: {critique}\\n\\n\"\n",
        "          \"Generate instructions that would make it better. \"\n",
        "          \"Sort them by importance and return it as a list of tasks\",\n",
        "    context_size=0, max_tokens=1000)\n",
        "\n",
        "for t in tasks:\n",
        "    task = \"Given this text:\\n\\n\" \\\n",
        "            f\"```markdown\\n{txt}\\n```\\n\\n\" \\\n",
        "            f\"Make the text better by executing this task: '{t}' \" \\\n",
        "            f\"and integrate it into the given text, but keep the overall objective in mind.\"\n",
        "    txt = agent.execute_task(task, context_size=10, max_tokens=1000, formatting=\"markdown\")\n",
        "    final_result.append([task, txt])\n"
      ],
      "metadata": {
        "id": "iUGGzhcMQ_p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for debugging, you can see all intermediate results, simply uncomment the variable to check:\n",
        "\n",
        "#final_result  # for the evolution of the final text\n",
        "#agent._debug_queue  # in order to check all requests made to llms and vectorstores etc..."
      ],
      "metadata": {
        "id": "s61RXXDRaQde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final text\n",
        "\n",
        "after all the processing, here is the final text:"
      ],
      "metadata": {
        "id": "Wgn2Gb5Mas5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(txt)"
      ],
      "metadata": {
        "id": "XwjVmsV8Z9Y5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}