{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMjdeX-wRTIg"
   },
   "source": [
    "# Pydoxtools: Automated, LLM based article writing with information retrieval from a directory of files in fewer than 100 lines of code!\n",
    "\n",
    "At Xyntopia, we are excited to introduce our latest creation, Pydoxtools - a versatile Python library designed to streamline AI-powered document processing and information retrieval. This library is perfect for users who are new to programming and want to harness the power of AI in their projects.\n",
    "\n",
    "This article showcases an efficient method to automate article writing for your project using ChatGPT and Pydoxtools in fewer than 100 lines of code. The script demonstrates the following key functionalities:\n",
    "\n",
    "- Indexing a directory containing files with PyDoxTools\n",
    "- Employing an agent for information retrieval within those files\n",
    "- Auto-generating a text based on a set objective\n",
    "\n",
    "You can execute this notebook or simply refer to our concise script, which encompasses these steps in less than 100 lines of code:\n",
    "\n",
    "https://github.com/Xyntopia/pydoxtools/blob/main/examples/automatic_project_writing.py\n",
    "\n",
    "or open this notebook in colab:\n",
    "\n",
    "https://colab.research.google.com/github/Xyntopia/pydoxtools/blob/main/examples/automated_blog_writing.ipynb\n",
    "\n",
    "## Costs and API Key\n",
    "\n",
    "Please note that ChatGPT is a paid service, and running the script once will cost you about 2-5 cents. To use ChatGPT, you will need to generate an OpenAI API key by registering an account at https://platform.openai.com/account/api-keys. Remember to keep your API key secure and do not share it with anyone.\n",
    "\n",
    "We are working on an implementation which makes use of open source models which can do the same for free, locally on your computer. Additionally, Pydoxtools automatically caches all calls to ChatGPT. So subsequent runs usually turn out to be a little cheaper.\n",
    "\n",
    "### Safeguarding Your API Key in Google Colab\n",
    "\n",
    "When working with sensitive information like API keys, it's crucial to ensure their security. In Google Colab, you can save your API key in a separate file, allowing you to share the notebook without exposing the key. To do this, follow these simple steps:\n",
    "\n",
    "1. Execute the cell below to create a new file in your Colab environment. This file will store your API key, and it will be deleted automatically when the Colab runtime is terminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TMjdeX-wRTIg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!touch /tmp/openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMjdeX-wRTIg"
   },
   "source": [
    "2. Click on the following link to open the newly created file by clicking on the following link in colab: /tmp/openai_api_key\n",
    "\n",
    "3. Copy and paste your API key into the file, then save it.\n",
    "\n",
    "By following these steps, you can ensure the security of your API key while still being able to share your notebook with others. Happy coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGD2Nxt8JN4g"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Follow these simple steps to install and configure Pydoxtools for your projects:\n",
    "\n",
    "1. Install the Pydoxtools library by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E6dYMNYvFsMt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U pydoxtools[etl,inference]==0.6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installation, restart the runtime to load the newly installed libraries into Jupyter.\n",
    "\n",
    "2. Now we are loading the OPENAI_API_KEY from our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "U5y6M-UqT0EE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load the key as an environment variable:\n",
    "import os\n",
    "# load the key\n",
    "with open('/tmp/openai_api_key') as f:\n",
    "  os.environ['OPENAI_API_KEY']=f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbkcG16YWR3u"
   },
   "source": [
    "3. now we can initialize pydoxtools which will automatically make use of the OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xqOo-swAFlai",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/.cache/pypoetry/virtualenvs/pydoxtools-25iw_UDY-py3.10/lib/python3.10/site-packages/mf2py/parser.py:409: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if x is not \"\":\n",
      "/home/tom/.cache/pypoetry/virtualenvs/pydoxtools-25iw_UDY-py3.10/lib/python3.10/site-packages/mf2py/dom_helpers.py:144: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  results = [t for t in text_collection(el, replace_img, img_to_src, base_url) if t is not '']\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import dask\n",
    "from chromadb.config import Settings\n",
    "\n",
    "import pydoxtools as pdx\n",
    "from pydoxtools import agent as ag\n",
    "from pydoxtools.settings import settings\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"pydoxtools.document\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GkFQIXDICYM"
   },
   "source": [
    "## configuration\n",
    "\n",
    "Pydoxtools can be configured in various ways for this example we are using two settings:\n",
    "\n",
    "- Pydoxtools uses dask in the background to handle large indexes and databases. We could even index terabytes of data this way! For this example though, we are setting the dask scheduler to \"synchronous\" so that we can see everything thats happening locally and make it easy to debug the script.\n",
    "- Pydoxtools has a caching mechanism which caches calls to pydoxtoos.Document. This helps during development for much faster execution on subsequent runs (for example the vector index creation or extraction of other information from documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "O-PwVOwsHnDH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pydoxtools.DocumentBag uses a dask scheduler for parallel computing\n",
    "# in the background. For easier debugging, we set this to \"synchronous\"\n",
    "dask.config.set(scheduler='synchronous')\n",
    "# dask.config.set(scheduler='multiprocessing') # can als be used...\n",
    "\n",
    "settings.PDX_ENABLE_DISK_CACHE = True  # turn on caching for pydoxtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiQ2p-cLcvyu"
   },
   "source": [
    "## download our project\n",
    "\n",
    "In order for our program to work, we need to provide the AI with information. In this case we are using files in a directory as a source of information! We are simply downloading the \"Pydoxtools\" project from github. Essentialy pydoxtools is writing about itself :-). You could also mount a google drive here or simply load a folder on your computer if you're running this notebook locally on your computer.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YB0Lh2uJIemO"
   },
   "outputs": [],
   "source": [
    "!cd /content\n",
    "!git clone https://github.com/Xyntopia/pydoxtools.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-kWx8q7IT_4"
   },
   "source": [
    "## Index initialization\n",
    "\n",
    "In order for an LLM like ChatGPT to retrieve the information it needs to be saved in a \"vectorformat\". This way we can retrieve relevant information using nearest neighbour search. We are using ChromaDB here for this purpose, but there are many other choices available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUhM1QhAH7uj"
   },
   "outputs": [],
   "source": [
    "##### Use chromadb as a vectorstore #####\n",
    "chroma_settings = Settings(\n",
    "    chroma_db_impl=\"duckdb+parquet\",\n",
    "    persist_directory=str(settings.PDX_CACHE_DIR_BASE / \"chromadb\"),\n",
    "    anonymized_telemetry=False\n",
    ")\n",
    "\n",
    "# create our source of information. It creates a list of documents\n",
    "# in pydoxtools called \"pydoxtools.DocumentBag\" (which itself holds a list of pydoxtools.Document) and\n",
    "# here we choose to use pydoxtools itself as an information source!\n",
    "root_dir = \"/content/pydoxtools\"\n",
    "ds = pdx.DocumentBag(\n",
    "    source=root_dir,\n",
    "    exclude=[  # ignore some files which make the indexing rather inefficient\n",
    "        '.git/', '.idea/', '/node_modules', '/dist',\n",
    "        '/__pycache__/', '.pytest_cache/', '.chroma', '.svg', '.lock',\n",
    "        \"/site/\"\n",
    "    ],\n",
    "    forgiving_extracts=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeKUMGR1J_CJ"
   },
   "source": [
    "## Initialize agent, give it a writing objective and compute the index\n",
    "\n",
    "Now that we have everything setup, we can initialize our LLM Agent with the provided information.\n",
    "For the [pydoxtools](https://github.com/Xyntopia/pydoxtools) project in this example, computing the index will take about 5-10 minutes. In total there will be about 4000 text snippets in the vector index for the  project after finishing the computation.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0_Qak1aIROq"
   },
   "outputs": [],
   "source": [
    "final_result = []\n",
    "\n",
    "agent = ag.LLMAgent(\n",
    "    vector_store=chroma_settings,\n",
    "    objective=\"Write a blog post, introducing a new library (which was developed by us, \"\n",
    "              \"the company 'Xyntopia') to \"\n",
    "              \"visitors of our corporate webpage, which might want to use the pydoxtools library but \"\n",
    "              \"have no idea about programming. Make sure, the text is about half a page long.\",\n",
    "    data_source=ds\n",
    ")\n",
    "agent.pre_compute_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNt1SdADQiUA"
   },
   "source": [
    "## Search for relevant Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jRmKi6MQtdV"
   },
   "source": [
    "The agent is able to store information as question/answer pairs and makes use of that information when executing tasks. In order to get our algorithm running a bit more quickly, we answer a basic question manually, to get the algorithm started more quickly... In a real app you could ask questions like this in a user-dialog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLG6v7nLKF3D"
   },
   "outputs": [],
   "source": [
    "agent.add_question(question=\"Can you please provide the main topic of the project or some primary \"\n",
    "                            \"keywords related to the project, \"\n",
    "                            \"to help with identifying the relevant files in the directory?\",\n",
    "                    answer=\"python library, AI, pipelines\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7be7qww_Q4q1"
   },
   "source": [
    "Having this information, we ask the agent to come up with a few more questions that it needs to answer before being able to write the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUPcDZiEQ3iU"
   },
   "outputs": [],
   "source": [
    "# first, gather some basic information...\n",
    "questions = agent.execute_task(\n",
    "  task=\"What additional information do you need to create a first, very short outline as a draft? \" \\\n",
    "        \"provide it as a ranked list of questions\", save_task=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having created this list of questions, we can now ask the agent to research them by itself. It will automatically\n",
    "use the index we computed above for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NUPcDZiEQ3iU",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# we only use the first 5 provided questions to make it faster ;).\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241m.\u001b[39mresearch_questions(questions[:\u001b[38;5;241m5\u001b[39m], allowed_documents\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/markdown\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "# we only use the first 5 provided questions to make it faster ;).\n",
    "agent.research_questions(questions[:5], allowed_documents=[\"text/markdown\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjqTJ_20RB6o"
   },
   "source": [
    "After retrieving this information we can tell the agent t write the text. We tell it to automatically make use of the information by setting the \"context_size\" parameter to a value greater than 0. This represents the pieces of stored information that it will use to fulfill the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUGGzhcMQ_p2"
   },
   "outputs": [],
   "source": [
    "txt = agent.execute_task(task=\"Complete the overall objective, formulate the text \"\n",
    "                              \"based on answered questions and format it in markdown.\",\n",
    "                          context_size=20, max_tokens=1000, formatting=\"txt\")\n",
    "final_result.append(txt)  # add a first draft to the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having our first draft of the text, lets critize it to improve the quality! Then with this\n",
    "critique create a new list of tasks that we can give to the agent to execute one-by-one. Gradually improving our text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUGGzhcMQ_p2"
   },
   "outputs": [],
   "source": [
    "critique = agent.execute_task(task=\"Given this text:\\n\\n```markdown\\n{txt}\\n```\"\n",
    "                                    \"\\n\\nlist 5 points of critique about the text\",\n",
    "                              context_size=0, max_tokens=1000)\n",
    "\n",
    "tasks = agent.execute_task(\n",
    "    task=\"Given this text:\\n\\n```markdown\\n{txt}\\n```\\n\\n\"\n",
    "          f\"and its critique: {critique}\\n\\n\"\n",
    "          \"Generate instructions that would make it better. \"\n",
    "          \"Sort them by importance and return it as a list of tasks\",\n",
    "    context_size=0, max_tokens=1000)\n",
    "\n",
    "for t in tasks:\n",
    "    task = \"Given this text:\\n\\n\" \\\n",
    "            f\"```markdown\\n{txt}\\n```\\n\\n\" \\\n",
    "            f\"Make the text better by executing this task: '{t}' \" \\\n",
    "            f\"and integrate it into the given text, but keep the overall objective in mind.\"\n",
    "    txt = agent.execute_task(task, context_size=10, max_tokens=1000, formatting=\"markdown\")\n",
    "    final_result.append([task, txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s61RXXDRaQde"
   },
   "outputs": [],
   "source": [
    "# for debugging, you can see all intermediate results, simply uncomment the variable to check:\n",
    "\n",
    "#final_result  # for the evolution of the final text\n",
    "#agent._debug_queue  # in order to check all requests made to llms and vectorstores etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wgn2Gb5Mas5g"
   },
   "source": [
    "## Final text\n",
    "\n",
    "After all the processing is finally done, here is the final text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwjVmsV8Z9Y5"
   },
   "outputs": [],
   "source": [
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Pydoxtools is a powerful and user-friendly Python library that makes it easy to harness the power of AI for document processing and information retrieval. Whether you are new to programming or an experienced developer, Pydoxtools can help you streamline your projects and achieve your goals. Give it a try today and experience the benefits for yourself!\n",
    "\n",
    "Get more information under the following links:\n",
    "\n",
    "- [https://pydoxtools.xyntopia.com]()\n",
    "- [https://github.com/xyntopia/pydoxtools]()\n",
    "- [https://www.xyntopia.com]()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
