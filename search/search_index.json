{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Pydoxtools Documentation! Readme Readme Visualization of the Extraction logic The extraction logic for different file types can be visualized bydoing something like this: doc = Document(fobj=make_path_absolute(\"./data/demo.docx\"), document_type=\".docx\") # for the currently loaded file type: doc.logic_graph(image_path=settings._PYDOXTOOLS_DIR / \"docs/images/document_logic_docx.svg\") # for the doc.logic_graph(image_path=settings._PYDOXTOOLS_DIR / \"docs/images/document_logic_png.svg\", document_logic_id=\".png\") This way we can generate the pipelines for different filetypes: docx png (click on links to open the images!) This also works for custom pipelines! Reference Bases: document_base . Pipeline A standard document configuration which should work for most documents. in order to load a document simply do this from pydoxtools import Document doc = Document(fobj=./data/demo.docx, document_type=\".docx\") You can then access any extracted data by calling doc.x(\"addresses\") doc.x(\"entities\") doc.x(\"full_text\") etc... a list of all available extraction data can be called like this doc.x_funcs() In order to declare a different logic it is best to take this logic for basic documents here as a starting point. inherited classes can override any part of the graph. It is possible to exchange/override/extend or introduce extraction logic for individual file types (including the generic one: \" \") such as .html extractors, .pdf, .txt etc.. strings inside a document class indicate the inclusion of that document type logic but with a lower priority this way a directed extraction graph gets built. This only counts for the current class that is being defined though!! Example extension logic for an OCR extractor which converts images into text: \"image\": [ OCRExtractor() .pipe(file=\"raw_content\") .out(\"ocr_pdf_file\") .cache(), ], the first base doc types have priority over the last ones so here .png > image > .pdf \".png\": [\"image\", \".pdf\"], \".jpeg\": [\"image\", \".pdf\"], \".jpg\": [\"image\", \".pdf\"], \".tif\": [\"image\", \".pdf\"], \".tiff\": [\"image\", \".pdf\"], the \"*\" gets overwritten by functions above \"*\": [...] This logic introduced new \"image\" code block and searches for filetypes \".png\", \".jpeg\", \".jpg\", \".tif\", \".tiff\" Each function (or node) in the extraction logic gets fed its input-parameters by the \"pipe\" command. These parameters can be configured on document creation if some of them are declared using the \"config\" command. These arguments can be overwritten by new logic in inherited documents or document types that are higher up in the hierarchy. The argument precedence is hereby as follows: python-class-member < extractor-graph-function < config","title":"Home"},{"location":"#welcome-to-pydoxtools-documentation","text":"","title":"Welcome to Pydoxtools Documentation!"},{"location":"#readme","text":"Readme","title":"Readme"},{"location":"#visualization-of-the-extraction-logic","text":"The extraction logic for different file types can be visualized bydoing something like this: doc = Document(fobj=make_path_absolute(\"./data/demo.docx\"), document_type=\".docx\") # for the currently loaded file type: doc.logic_graph(image_path=settings._PYDOXTOOLS_DIR / \"docs/images/document_logic_docx.svg\") # for the doc.logic_graph(image_path=settings._PYDOXTOOLS_DIR / \"docs/images/document_logic_png.svg\", document_logic_id=\".png\") This way we can generate the pipelines for different filetypes: docx png (click on links to open the images!) This also works for custom pipelines!","title":"Visualization of the Extraction logic"},{"location":"#reference","text":"Bases: document_base . Pipeline A standard document configuration which should work for most documents. in order to load a document simply do this from pydoxtools import Document doc = Document(fobj=./data/demo.docx, document_type=\".docx\") You can then access any extracted data by calling doc.x(\"addresses\") doc.x(\"entities\") doc.x(\"full_text\")","title":"Reference"},{"location":"#pydoxtools.Document--etc","text":"a list of all available extraction data can be called like this doc.x_funcs() In order to declare a different logic it is best to take this logic for basic documents here as a starting point. inherited classes can override any part of the graph. It is possible to exchange/override/extend or introduce extraction logic for individual file types (including the generic one: \" \") such as .html extractors, .pdf, .txt etc.. strings inside a document class indicate the inclusion of that document type logic but with a lower priority this way a directed extraction graph gets built. This only counts for the current class that is being defined though!! Example extension logic for an OCR extractor which converts images into text: \"image\": [ OCRExtractor() .pipe(file=\"raw_content\") .out(\"ocr_pdf_file\") .cache(), ],","title":"etc..."},{"location":"#pydoxtools.Document--the-first-base-doc-types-have-priority-over-the-last-ones","text":"","title":"the first base doc types have priority over the last ones"},{"location":"#pydoxtools.Document--so-here-png-image-pdf","text":"\".png\": [\"image\", \".pdf\"], \".jpeg\": [\"image\", \".pdf\"], \".jpg\": [\"image\", \".pdf\"], \".tif\": [\"image\", \".pdf\"], \".tiff\": [\"image\", \".pdf\"],","title":"so here .png &gt; image &gt; .pdf"},{"location":"#pydoxtools.Document--the-gets-overwritten-by-functions-above","text":"\"*\": [...] This logic introduced new \"image\" code block and searches for filetypes \".png\", \".jpeg\", \".jpg\", \".tif\", \".tiff\" Each function (or node) in the extraction logic gets fed its input-parameters by the \"pipe\" command. These parameters can be configured on document creation if some of them are declared using the \"config\" command. These arguments can be overwritten by new logic in inherited documents or document types that are higher up in the hierarchy. The argument precedence is hereby as follows: python-class-member < extractor-graph-function < config","title":"the \"*\" gets overwritten by functions above"},{"location":"readme_cp/","text":"pydoxtools Pydoxtools is a library that provides a sophisticated interface for reading and writing documents, designed to work with AI models such as GPT, Alpaca, and Huggingface. It offers functionalities such as: Table extraction Document analysis and question-answering Task relation creation Entity, address identification and more List and keyword extraction Data normalization, translation, and cleaning The library allows for the creation of complex extraction pipelines for batch-processing of documents by defining them as a lazily-executed graph. Teaser When using pydoxtools with chatgpt, we need to make sure that you are using a import pydoxtools as pdx # create a document from a file, string, bytestring, file-like object # or even an url: doc = Document( \"https://www.raspberrypi.org/app/uploads/2012/12/quick-start-guide-v1.1.pdf\", document_type=\".pdf\" ) # extract the table as a pandas dataframe: print(doc.tables_df) print(doc.answers([\"how much power does it need?\"])[0][0][0]) print(doc.chat_answers([\"who is the target group of this document?\"])[0].content) print(doc.chat_answers([\"Answer if a 5-year old would be able to follow these instructions?\"])[0].content) # ask a question about the document: CLI TODO... Installation pip install pydoxtools[etl, inference] # TODO: explain some dependencies (especially pytorch) Examples analyze documents using any sort of model from huggingface... analyze documents using a custom model download a pdf from URL generate document keywords extract tables download document from URL \"manually\" and then feed to document extract addresses extract addresses and use this information for the qam Development --> see License This project is licensed under the terms of MIT license. You can check the compatibility using the following tool in a venv environment in a production setting: pip install pip-licenses pip-licenses | grep -Ev 'MIT License|BSD License|Apache Software License|Python Software Foundation License|Apache 2.0|MIT|Apache License 2.0|hnswlib|Pillow|new BSD|BSD' list of libraries, that this project is based on: list","title":"pydoxtools"},{"location":"readme_cp/#pydoxtools","text":"Pydoxtools is a library that provides a sophisticated interface for reading and writing documents, designed to work with AI models such as GPT, Alpaca, and Huggingface. It offers functionalities such as: Table extraction Document analysis and question-answering Task relation creation Entity, address identification and more List and keyword extraction Data normalization, translation, and cleaning The library allows for the creation of complex extraction pipelines for batch-processing of documents by defining them as a lazily-executed graph.","title":"pydoxtools"},{"location":"readme_cp/#teaser","text":"When using pydoxtools with chatgpt, we need to make sure that you are using a import pydoxtools as pdx # create a document from a file, string, bytestring, file-like object # or even an url: doc = Document( \"https://www.raspberrypi.org/app/uploads/2012/12/quick-start-guide-v1.1.pdf\", document_type=\".pdf\" ) # extract the table as a pandas dataframe: print(doc.tables_df) print(doc.answers([\"how much power does it need?\"])[0][0][0]) print(doc.chat_answers([\"who is the target group of this document?\"])[0].content) print(doc.chat_answers([\"Answer if a 5-year old would be able to follow these instructions?\"])[0].content) # ask a question about the document:","title":"Teaser"},{"location":"readme_cp/#cli","text":"TODO...","title":"CLI"},{"location":"readme_cp/#installation","text":"pip install pydoxtools[etl, inference] # TODO: explain some dependencies (especially pytorch)","title":"Installation"},{"location":"readme_cp/#examples","text":"analyze documents using any sort of model from huggingface... analyze documents using a custom model download a pdf from URL generate document keywords extract tables download document from URL \"manually\" and then feed to document extract addresses extract addresses and use this information for the qam","title":"Examples"},{"location":"readme_cp/#development","text":"--> see","title":"Development"},{"location":"readme_cp/#license","text":"This project is licensed under the terms of MIT license. You can check the compatibility using the following tool in a venv environment in a production setting: pip install pip-licenses pip-licenses | grep -Ev 'MIT License|BSD License|Apache Software License|Python Software Foundation License|Apache 2.0|MIT|Apache License 2.0|hnswlib|Pillow|new BSD|BSD'","title":"License"},{"location":"readme_cp/#list-of-libraries-that-this-project-is-based-on","text":"list","title":"list of libraries, that this project is based on:"}]}