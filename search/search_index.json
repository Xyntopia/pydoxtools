{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Pydoxtools Documentation!","text":"<p>Readme</p>"},{"location":"#introduction","title":"Introduction","text":"<p>The main interface that pydoxtools uses are three classes:</p> <ul> <li>pydoxtools.Document</li> <li>pydoxtools.DocumentSet</li> <li>pydoxtools.Pipeline</li> </ul>"},{"location":"#analyzing-document","title":"Analyzing Document","text":"<p>Document &amp; DocumentSet are both using pydoxtools.Pipeline and predefine a complex pipeline to extract data from individual documents or a set of documents. A list of all the \"out-of-the-box\" featurs for each pipelin can be found in:</p> <p>-&gt; Pipelines</p>"},{"location":"#building-your-own-pipelines-for-example-with-llms","title":"Building your own Pipelines (for example with LLMs)","text":"<p>the Pipeline class can be used to build complex, custom pipelines which have several out-of-the-box features which makes them easy to use in modern pipelines involving the use of a lot of AI tools:</p> <ul> <li>they can be mixed, extended, (partially) overwritten with other pipelines</li> <li>they can export/import their data (yaml, json, python-dict),</li> <li>they can be configured &amp; optimized</li> <li>they can convert their data into pydoxtools.Document and pydoxtools.DocumentSet</li> </ul> <p>Additionally, in order to develop a custom pipeline, pydoxtools has a large library of pydoxtools.operators which can be used to build your custom pipeline. It usually makes sense to use pydoxtools.Document or pydoxtools.DocumentSet as a base for a new pipeline and only replace small parts of them in order to get desired custom functionality.</p>"},{"location":"#visualization-of-the-pipelines","title":"Visualization of the Pipelines","text":"<p>The pipelines can be visualized which helps a lot when developing your own pipeline on top of a complex pipeline such as the document pipeline. The extraction logic for different file types can be visualized like this:</p> <pre><code>doc = Document(fobj=make_path_absolute(\"./data/demo.docx\"), document_type=\".docx\")\n# for the currently loaded file type:\ndoc.logic_graph(image_path=settings._PYDOXTOOLS_DIR / \"docs/images/document_logic_docx.svg\")\n# for the \ndoc.logic_graph(image_path=settings._PYDOXTOOLS_DIR / \"docs/images/document_logic_png.svg\", document_logic_id=\".png\")\n</code></pre> <p>This way we can generate the pipelines for different filetypes:</p> <ul> <li>docx</li> <li>png   (click on links to open the images!)</li> </ul> <p>Pipelines for every supported file type can be found here.</p> <p>This also works for custom pipelines!</p> <p>In order to learn more continue to: Reference</p>"},{"location":"DEVELOPMENT/","title":"Development &amp; Contribution","text":"<p>The graph model of the library makes it very easy to extend it with new functionality.</p> <ul> <li>the document can be used as a base-model and overwritten with changes</li> <li>the graph can be changed dynamically</li> <li>new functions can be very easily integrated</li> </ul>"},{"location":"DEVELOPMENT/#pydoxtools-architecture","title":"Pydoxtools Architecture","text":"<p>--&gt; refer to \"document\"</p>"},{"location":"DEVELOPMENT/#contribution-guidelines","title":"Contribution Guidelines","text":""},{"location":"pipelines/","title":"Pipelines","text":"<p>This documents the output values of the nodes of each pipeline that  can be accessed through the pipeline interface.</p>"},{"location":"pipelines/#pydoxtoolsdocument","title":"pydoxtools.Document","text":""},{"location":"pipelines/#raw_content","title":"raw_content","text":"<p>Can be called using:</p> <pre><code>doc.x('raw_content')\n# or\ndoc.raw_content\n</code></pre> <p>return type : bytes | str</p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#full_text","title":"full_text","text":"<p>Can be called using:</p> <pre><code>doc.x('full_text')\n# or\ndoc.full_text\n</code></pre> <p>return type :  <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#clean_text","title":"clean_text","text":"<p>Can be called using:</p> <pre><code>doc.x('clean_text')\n# or\ndoc.clean_text\n</code></pre> <p>return type :  <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#text_box_elements","title":"text_box_elements","text":"<p>Can be called using:</p> <pre><code>doc.x('text_box_elements')\n# or\ndoc.text_box_elements\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#text_box_list","title":"text_box_list","text":"<p>Can be called using:</p> <pre><code>doc.x('text_box_list')\n# or\ndoc.text_box_list\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#tables_df","title":"tables_df","text":"<p>Can be called using:</p> <pre><code>doc.x('tables_df')\n# or\ndoc.tables_df\n</code></pre> <p>return type : str | list[str] | list[pandas.core.frame.DataFrame]</p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#tables_dict","title":"tables_dict","text":"<p>Can be called using:</p> <pre><code>doc.x('tables_dict')\n# or\ndoc.tables_dict\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#tables","title":"tables","text":"<p>Can be called using:</p> <pre><code>doc.x('tables')\n# or\ndoc.tables\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#addresses","title":"addresses","text":"<p>Can be called using:</p> <pre><code>doc.x('addresses')\n# or\ndoc.addresses\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#num_pages","title":"num_pages","text":"<p>Can be called using:</p> <pre><code>doc.x('num_pages')\n# or\ndoc.num_pages\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#num_words","title":"num_words","text":"<p>Can be called using:</p> <pre><code>doc.x('num_words')\n# or\ndoc.num_words\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#num_sents","title":"num_sents","text":"<p>Can be called using:</p> <pre><code>doc.x('num_sents')\n# or\ndoc.num_sents\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#a_d_ratio","title":"a_d_ratio","text":"<p>Can be called using:</p> <pre><code>doc.x('a_d_ratio')\n# or\ndoc.a_d_ratio\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#language","title":"language","text":"<p>Can be called using:</p> <pre><code>doc.x('language')\n# or\ndoc.language\n</code></pre> <p>return type :  <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#spacy_model_size","title":"spacy_model_size","text":"<p>Can be called using:</p> <pre><code>doc.x('spacy_model_size')\n# or\ndoc.spacy_model_size\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#spacy_model","title":"spacy_model","text":"<p>Can be called using:</p> <pre><code>doc.x('spacy_model')\n# or\ndoc.spacy_model\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#spacy_doc","title":"spacy_doc","text":"<p>Can be called using:</p> <pre><code>doc.x('spacy_doc')\n# or\ndoc.spacy_doc\n</code></pre> <p>return type : dict[str, typing.Any]</p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#spacy_nlp","title":"spacy_nlp","text":"<p>Can be called using:</p> <pre><code>doc.x('spacy_nlp')\n# or\ndoc.spacy_nlp\n</code></pre> <p>return type : dict[str, typing.Any]</p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#spacy_vectors","title":"spacy_vectors","text":"<p>Can be called using:</p> <pre><code>doc.x('spacy_vectors')\n# or\ndoc.spacy_vectors\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#spacy_embeddings","title":"spacy_embeddings","text":"<p>Can be called using:</p> <pre><code>doc.x('spacy_embeddings')\n# or\ndoc.spacy_embeddings\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#spacy_sents","title":"spacy_sents","text":"<p>Can be called using:</p> <pre><code>doc.x('spacy_sents')\n# or\ndoc.spacy_sents\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#spacy_noun_chunks","title":"spacy_noun_chunks","text":"<p>Can be called using:</p> <pre><code>doc.x('spacy_noun_chunks')\n# or\ndoc.spacy_noun_chunks\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#entities","title":"entities","text":"<p>Can be called using:</p> <pre><code>doc.x('entities')\n# or\ndoc.entities\n</code></pre> <p>return type : dict[str, list[str]]</p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#url","title":"url","text":"<p>Can be called using:</p> <pre><code>doc.x('url')\n# or\ndoc.url\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#sents","title":"sents","text":"<p>Can be called using:</p> <pre><code>doc.x('sents')\n# or\ndoc.sents\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#noun_chunks","title":"noun_chunks","text":"<p>Can be called using:</p> <pre><code>doc.x('noun_chunks')\n# or\ndoc.noun_chunks\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#vector","title":"vector","text":"<p>Can be called using:</p> <pre><code>doc.x('vector')\n# or\ndoc.vector\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#sent_vecs","title":"sent_vecs","text":"<p>Can be called using:</p> <pre><code>doc.x('sent_vecs')\n# or\ndoc.sent_vecs\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#sent_ids","title":"sent_ids","text":"<p>Can be called using:</p> <pre><code>doc.x('sent_ids')\n# or\ndoc.sent_ids\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#noun_vecs","title":"noun_vecs","text":"<p>Can be called using:</p> <pre><code>doc.x('noun_vecs')\n# or\ndoc.noun_vecs\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#noun_ids","title":"noun_ids","text":"<p>Can be called using:</p> <pre><code>doc.x('noun_ids')\n# or\ndoc.noun_ids\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#text_segments","title":"text_segments","text":"<p>Can be called using:</p> <pre><code>doc.x('text_segments')\n# or\ndoc.text_segments\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#text_segment_model","title":"text_segment_model","text":"<p>Can be called using:</p> <pre><code>doc.x('text_segment_model')\n# or\ndoc.text_segment_model\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#text_segment_only_tokenizer","title":"text_segment_only_tokenizer","text":"<p>Can be called using:</p> <pre><code>doc.x('text_segment_only_tokenizer')\n# or\ndoc.text_segment_only_tokenizer\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#text_segment_vectors","title":"text_segment_vectors","text":"<p>Can be called using:</p> <pre><code>doc.x('text_segment_vectors')\n# or\ndoc.text_segment_vectors\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#noun_index","title":"noun_index","text":"<p>Can be called using:</p> <pre><code>doc.x('noun_index')\n# or\ndoc.noun_index\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#vectorizer","title":"vectorizer","text":"<p>Can be called using:</p> <pre><code>doc.x('vectorizer')\n# or\ndoc.vectorizer\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#noun_query","title":"noun_query","text":"<p>Can be called using:</p> <pre><code>doc.x('noun_query')\n# or\ndoc.noun_query\n</code></pre> <p>return type : typing.Callable</p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#noun_graph","title":"noun_graph","text":"<p>Can be called using:</p> <pre><code>doc.x('noun_graph')\n# or\ndoc.noun_graph\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#top_k_text_rank_keywords","title":"top_k_text_rank_keywords","text":"<p>Can be called using:</p> <pre><code>doc.x('top_k_text_rank_keywords')\n# or\ndoc.top_k_text_rank_keywords\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#textrank_keywords","title":"textrank_keywords","text":"<p>Can be called using:</p> <pre><code>doc.x('textrank_keywords')\n# or\ndoc.textrank_keywords\n</code></pre> <p>return type : set[str]</p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#keywords","title":"keywords","text":"<p>Can be called using:</p> <pre><code>doc.x('keywords')\n# or\ndoc.keywords\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#sent_index","title":"sent_index","text":"<p>Can be called using:</p> <pre><code>doc.x('sent_index')\n# or\ndoc.sent_index\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#sent_query","title":"sent_query","text":"<p>Can be called using:</p> <pre><code>doc.x('sent_query')\n# or\ndoc.sent_query\n</code></pre> <p>return type : typing.Callable</p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#sent_graph","title":"sent_graph","text":"<p>Can be called using:</p> <pre><code>doc.x('sent_graph')\n# or\ndoc.sent_graph\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#top_k_text_rank_sentences","title":"top_k_text_rank_sentences","text":"<p>Can be called using:</p> <pre><code>doc.x('top_k_text_rank_sentences')\n# or\ndoc.top_k_text_rank_sentences\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#textrank_sents","title":"textrank_sents","text":"<p>Can be called using:</p> <pre><code>doc.x('textrank_sents')\n# or\ndoc.textrank_sents\n</code></pre> <p>return type : set[str]</p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#summarizer_model","title":"summarizer_model","text":"<p>Can be called using:</p> <pre><code>doc.x('summarizer_model')\n# or\ndoc.summarizer_model\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#summarizer_token_overlap","title":"summarizer_token_overlap","text":"<p>Can be called using:</p> <pre><code>doc.x('summarizer_token_overlap')\n# or\ndoc.summarizer_token_overlap\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#summarizer_max_text_len","title":"summarizer_max_text_len","text":"<p>Can be called using:</p> <pre><code>doc.x('summarizer_max_text_len')\n# or\ndoc.summarizer_max_text_len\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#summary","title":"summary","text":"<p>Can be called using:</p> <pre><code>doc.x('summary')\n# or\ndoc.summary\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#qam_model_id","title":"qam_model_id","text":"<p>Can be called using:</p> <pre><code>doc.x('qam_model_id')\n# or\ndoc.qam_model_id\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#answers","title":"answers","text":"<p>Can be called using:</p> <pre><code>doc.x('answers')\n# or\ndoc.answers\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#openai_chat_model_id","title":"openai_chat_model_id","text":"<p>Can be called using:</p> <pre><code>doc.x('openai_chat_model_id')\n# or\ndoc.openai_chat_model_id\n</code></pre> <p>return type : </p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#chat_answers","title":"chat_answers","text":"<p>Can be called using:</p> <pre><code>doc.x('chat_answers')\n# or\ndoc.chat_answers\n</code></pre> <p>return type : typing.Callable[[list[str], list[str] | str], list[str]]</p> <p>supports pipelines : *,.docx,.epub,.html,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,.yaml,dict,image,pandoc</p>"},{"location":"pipelines/#page_set","title":"page_set","text":"<p>Can be called using:</p> <pre><code>doc.x('page_set')\n# or\ndoc.page_set\n</code></pre> <p>return type : </p> <p>supports pipelines : .jpeg,.jpg,.pdf,.png,.tif,.tiff,image</p>"},{"location":"pipelines/#pages_bbox","title":"pages_bbox","text":"<p>Can be called using:</p> <pre><code>doc.x('pages_bbox')\n# or\ndoc.pages_bbox\n</code></pre> <p>return type : </p> <p>supports pipelines : .jpeg,.jpg,.pdf,.png,.tif,.tiff,image</p>"},{"location":"pipelines/#elements","title":"elements","text":"<p>Can be called using:</p> <pre><code>doc.x('elements')\n# or\ndoc.elements\n</code></pre> <p>return type : </p> <p>supports pipelines : .jpeg,.jpg,.pdf,.png,.tif,.tiff,image</p>"},{"location":"pipelines/#meta","title":"meta","text":"<p>Can be called using:</p> <pre><code>doc.x('meta')\n# or\ndoc.meta\n</code></pre> <p>return type : </p> <p>supports pipelines : .jpeg,.jpg,.pdf,.png,.tif,.tiff,image</p>"},{"location":"pipelines/#line_elements","title":"line_elements","text":"<p>Can be called using:</p> <pre><code>doc.x('line_elements')\n# or\ndoc.line_elements\n</code></pre> <p>return type : </p> <p>supports pipelines : .jpeg,.jpg,.pdf,.png,.tif,.tiff,image</p>"},{"location":"pipelines/#graphic_elements","title":"graphic_elements","text":"<p>Can be called using:</p> <pre><code>doc.x('graphic_elements')\n# or\ndoc.graphic_elements\n</code></pre> <p>return type : </p> <p>supports pipelines : .jpeg,.jpg,.pdf,.png,.tif,.tiff,image</p>"},{"location":"pipelines/#lists","title":"lists","text":"<p>Can be called using:</p> <pre><code>doc.x('lists')\n# or\ndoc.lists\n</code></pre> <p>return type : str | list[str] | list[pandas.core.frame.DataFrame]</p> <p>supports pipelines : .docx,.epub,.jpeg,.jpg,.markdown,.md,.odt,.pdf,.png,.rtf,.tif,.tiff,image,pandoc</p>"},{"location":"pipelines/#table_box_levels","title":"table_box_levels","text":"<p>Can be called using:</p> <pre><code>doc.x('table_box_levels')\n# or\ndoc.table_box_levels\n</code></pre> <p>return type : </p> <p>supports pipelines : .jpeg,.jpg,.pdf,.png,.tif,.tiff,image</p>"},{"location":"pipelines/#table_candidates","title":"table_candidates","text":"<p>Can be called using:</p> <pre><code>doc.x('table_candidates')\n# or\ndoc.table_candidates\n</code></pre> <p>return type : </p> <p>supports pipelines : .jpeg,.jpg,.pdf,.png,.tif,.tiff,image</p>"},{"location":"pipelines/#table_df0","title":"table_df0","text":"<p>Can be called using:</p> <pre><code>doc.x('table_df0')\n# or\ndoc.table_df0\n</code></pre> <p>return type : </p> <p>supports pipelines : .jpeg,.jpg,.pdf,.png,.tif,.tiff,image</p>"},{"location":"pipelines/#titles","title":"titles","text":"<p>Can be called using:</p> <pre><code>doc.x('titles')\n# or\ndoc.titles\n</code></pre> <p>return type : </p> <p>supports pipelines : .html,.jpeg,.jpg,.pdf,.png,.tif,.tiff,image</p>"},{"location":"pipelines/#side_titles","title":"side_titles","text":"<p>Can be called using:</p> <pre><code>doc.x('side_titles')\n# or\ndoc.side_titles\n</code></pre> <p>return type : </p> <p>supports pipelines : .jpeg,.jpg,.pdf,.png,.tif,.tiff,image</p>"},{"location":"pipelines/#html_keywords_str","title":"html_keywords_str","text":"<p>Can be called using:</p> <pre><code>doc.x('html_keywords_str')\n# or\ndoc.html_keywords_str\n</code></pre> <p>return type : </p> <p>supports pipelines : .html</p>"},{"location":"pipelines/#main_content_clean_html","title":"main_content_clean_html","text":"<p>Can be called using:</p> <pre><code>doc.x('main_content_clean_html')\n# or\ndoc.main_content_clean_html\n</code></pre> <p>return type : </p> <p>supports pipelines : .html</p>"},{"location":"pipelines/#goose_article","title":"goose_article","text":"<p>Can be called using:</p> <pre><code>doc.x('goose_article')\n# or\ndoc.goose_article\n</code></pre> <p>return type : </p> <p>supports pipelines : .html</p>"},{"location":"pipelines/#main_content","title":"main_content","text":"<p>Can be called using:</p> <pre><code>doc.x('main_content')\n# or\ndoc.main_content\n</code></pre> <p>return type : </p> <p>supports pipelines : .html</p>"},{"location":"pipelines/#schemadata","title":"schemadata","text":"<p>Can be called using:</p> <pre><code>doc.x('schemadata')\n# or\ndoc.schemadata\n</code></pre> <p>return type : </p> <p>supports pipelines : .html</p>"},{"location":"pipelines/#final_urls","title":"final_urls","text":"<p>Can be called using:</p> <pre><code>doc.x('final_urls')\n# or\ndoc.final_urls\n</code></pre> <p>return type : </p> <p>supports pipelines : .html</p>"},{"location":"pipelines/#pdf_links","title":"pdf_links","text":"<p>Can be called using:</p> <pre><code>doc.x('pdf_links')\n# or\ndoc.pdf_links\n</code></pre> <p>return type : </p> <p>supports pipelines : .html</p>"},{"location":"pipelines/#title","title":"title","text":"<p>Can be called using:</p> <pre><code>doc.x('title')\n# or\ndoc.title\n</code></pre> <p>return type : </p> <p>supports pipelines : .html</p>"},{"location":"pipelines/#short_title","title":"short_title","text":"<p>Can be called using:</p> <pre><code>doc.x('short_title')\n# or\ndoc.short_title\n</code></pre> <p>return type : </p> <p>supports pipelines : .html</p>"},{"location":"pipelines/#urls","title":"urls","text":"<p>Can be called using:</p> <pre><code>doc.x('urls')\n# or\ndoc.urls\n</code></pre> <p>return type : </p> <p>supports pipelines : .html</p>"},{"location":"pipelines/#main_image","title":"main_image","text":"<p>Can be called using:</p> <pre><code>doc.x('main_image')\n# or\ndoc.main_image\n</code></pre> <p>return type : </p> <p>supports pipelines : .html</p>"},{"location":"pipelines/#html_keywords","title":"html_keywords","text":"<p>Can be called using:</p> <pre><code>doc.x('html_keywords')\n# or\ndoc.html_keywords\n</code></pre> <p>return type : </p> <p>supports pipelines : .html</p>"},{"location":"pipelines/#pandoc_document","title":"pandoc_document","text":"<p>Can be called using:</p> <pre><code>doc.x('pandoc_document')\n# or\ndoc.pandoc_document\n</code></pre> <p>return type : Pandoc(Meta, [Block])</p> <p>supports pipelines : .docx,.epub,.markdown,.md,.odt,.rtf,pandoc</p>"},{"location":"pipelines/#output_format","title":"output_format","text":"<p>Can be called using:</p> <pre><code>doc.x('output_format')\n# or\ndoc.output_format\n</code></pre> <p>return type : </p> <p>supports pipelines : .docx,.epub,.markdown,.md,.odt,.rtf,pandoc</p>"},{"location":"pipelines/#clean_format","title":"clean_format","text":"<p>Can be called using:</p> <pre><code>doc.x('clean_format')\n# or\ndoc.clean_format\n</code></pre> <p>return type : </p> <p>supports pipelines : .docx,.epub,.markdown,.md,.odt,.rtf,pandoc</p>"},{"location":"pipelines/#pandoc_blocks","title":"pandoc_blocks","text":"<p>Can be called using:</p> <pre><code>doc.x('pandoc_blocks')\n# or\ndoc.pandoc_blocks\n</code></pre> <p>return type : list['pandoc.types.Block']</p> <p>supports pipelines : .docx,.epub,.markdown,.md,.odt,.rtf,pandoc</p>"},{"location":"pipelines/#headers","title":"headers","text":"<p>Can be called using:</p> <pre><code>doc.x('headers')\n# or\ndoc.headers\n</code></pre> <p>return type : str | list[str] | list[pandas.core.frame.DataFrame]</p> <p>supports pipelines : .docx,.epub,.markdown,.md,.odt,.rtf,pandoc</p>"},{"location":"pipelines/#ocr_lang","title":"ocr_lang","text":"<p>Can be called using:</p> <pre><code>doc.x('ocr_lang')\n# or\ndoc.ocr_lang\n</code></pre> <p>return type : </p> <p>supports pipelines : .jpeg,.jpg,.png,.tif,.tiff,image</p>"},{"location":"pipelines/#ocr_on","title":"ocr_on","text":"<p>Can be called using:</p> <pre><code>doc.x('ocr_on')\n# or\ndoc.ocr_on\n</code></pre> <p>return type : </p> <p>supports pipelines : .jpeg,.jpg,.png,.tif,.tiff,image</p>"},{"location":"pipelines/#ocr_pdf_file","title":"ocr_pdf_file","text":"<p>Can be called using:</p> <pre><code>doc.x('ocr_pdf_file')\n# or\ndoc.ocr_pdf_file\n</code></pre> <p>return type : </p> <p>supports pipelines : .jpeg,.jpg,.png,.tif,.tiff,image</p>"},{"location":"pipelines/#data","title":"data","text":"<p>Can be called using:</p> <pre><code>doc.x('data')\n# or\ndoc.data\n</code></pre> <p>return type : </p> <p>supports pipelines : .yaml,dict</p>"},{"location":"readme_cp/","title":"\ud83d\ude80 pydoxtools (Python Library) \ud83d\ude80","text":"<p>(WIP) Documentation</p> <p>Pydoxtools is a library that provides a sophisticated interface for reading and writing documents, designed to work with AI models such as GPT, Alpaca, and Huggingface. It offers functionalities such as:</p> <ul> <li>Table extraction</li> <li>Vector Index Creation</li> <li>Document analysis and question-answering</li> <li>Entity, address identification and more</li> <li>List and keyword extraction</li> <li>Data normalization, translation, and cleaning</li> </ul> <p>The library allows for the creation of complex extraction pipelines for batch-processing of documents by defining them as a lazily-executed graph.</p>"},{"location":"readme_cp/#installation","title":"Installation","text":"<p>While pydoxtools can already be installed through pip. Due to the many updates coming in right now, it is right now recommended to use the latest version from github as follows:</p> <pre><code>pip install -U \"pydoxtools[etl,inference] @ git+https://github.com/xyntopia/pydoxtools.git\"\n</code></pre> <p>Pydoxtools can be also be installed through pip which will become the recommended method once it becomes more stable:</p> <pre><code>pip install -U pydoxtools[etl,inference]\n</code></pre> <p>For loading additional file formats (docx, odt, epub) and images, checkout the additional &gt; Installation Options &lt;.</p>"},{"location":"readme_cp/#teaser","title":"Teaser","text":"<p>Experience a new level of convenience and efficiency in handling documents with Pydoxtools, and reimagine your data extraction pipelines! \ud83c\udfa9\u2728\ud83d\udcc4.</p> <pre><code>import pydoxtools as pdx\n\n# create a document from a file, string, bytestring, file-like object\n# or even an url:\ndoc = pdx.Document(\n    \"https://www.raspberrypi.org/app/uploads/2012/12/quick-start-guide-v1.1.pdf\", \n    document_type=\".pdf\"\n)\n</code></pre> <p>You can easily extract a large number of pre-defined information about your document. To get a list of possible operators use <code>print(doc.x_funcs)</code>.</p> <pre><code># extract tables from the pdf as a pandas dataframe:\nprint(doc.tables_df)\n</code></pre> <p>Some extraction operations need input when called. The model that should be used for the question answering can be specified through doc.config() and can be any model from huggingface.</p> <pre><code># ask a question about the document, using Q&amp;A Models (questionas answered locally!):\nprint(doc.answers([\"how much ram does it have?\"]))\n</code></pre> <p>others need an API key installed, if it refers to an online service.</p> <pre><code># ask a question about the document, using ChatGPT (we need the API key for ChatGPT!):\n# load the API key into an environment variable like this: \n#   \n# OPENAI_API_KEY=\"sk ....\"\n# \n# Do **NOT** use the key in your code. This could potentially cost you a lot of money...\nprint(doc.chat_answers([\"What is the target group of this document?\"])[0].content)\nprint(doc.chat_answers([\"Answer if a 5-year old would be able to follow these instructions?\"])[0].content)\n</code></pre>"},{"location":"readme_cp/#features","title":"Features","text":""},{"location":"readme_cp/#large-pipelines","title":"Large pipelines","text":"<p>Pydoxtools main feature is the ability to mix LLMs and other AI models in large, composable and customizable pipelines. As a teaser, check out this pipeline for *.png images from the repository including OCR, keyword extraction, vectorization and more. In this pipeline:</p> <ul> <li>Every node in an ellipse can be called as an attribute of the document-analysis pipeline.</li> <li>Every execution-path is lazily executed throughout the entire graph.</li> <li>Every node is cached by default (can be turned off).</li> <li>Every piece of this pipeline can be replaced by a customized version.</li> </ul> <p></p> <p>Pipelines can be mixed, partially overwritten and extended which gives you a lot of possibilities to extend and adapt the functionality for your specific use-case.</p> <p>Find out more about it in the documentation</p>"},{"location":"readme_cp/#pipeline-configuration","title":"Pipeline configuration","text":"<p>Pipelines can be configured. For example the local model used for question answering can be selected like this:</p> <pre><code>doc = Document(fobj=\"./data/PFR-PR23_BAT-110__V1.00_.pdf\"))\n        .config(qam_model_id='bert-large-uncased-whole-word-masking-finetuned-squad')\n</code></pre> <p>where \"qam_model_id\" can be any model from huggingface for question answering.</p> <pre><code>TODO: document how to configure a pipeline\n</code></pre>"},{"location":"readme_cp/#pdf-table-extraction-algorithms","title":"PDF table extraction algorithms","text":"<p>The library features its own sophisticated Table extraction algorithm which is benchmarked against a large pdf table dataset. In contrast to most other table extraction frameworks out there it does not require:</p> <ul> <li>extensive configuration</li> <li>no expensive deep neural networks which need a GPU</li> </ul> <p>This makes it possible to run analysis on PDF files with pydoxtools on CPU with very limited resources!</p>"},{"location":"readme_cp/#todo-describe-more-of-the-features-here","title":"TODO: Describe more of the features here...","text":""},{"location":"readme_cp/#use-cases","title":"Use Cases","text":"<ul> <li>analyze documents using any model from huggingface...</li> <li>analyze documents using a custom model</li> <li>download a pdf from URL</li> <li>generate document keywords</li> <li>extract tables</li> <li>download document from URL \"manually\" and then feed to document</li> <li>extract addresses</li> <li>extract addresses and use this information for the qam</li> <li>ingest documents into a vector db</li> </ul>"},{"location":"readme_cp/#installation-options","title":"Installation Options","text":""},{"location":"readme_cp/#supporting-docx-odt-epub","title":"Supporting .docx, .odt, *.epub","text":"<p>In order to be able to load docx, odt and rtf files, you have to install pandoc. Right now, the python pandoc library does not work with pandoc version &gt; 3.0.0. It is therefore recommended to install a version from here for your OS:</p> <p>https://github.com/jgm/pandoc/releases/tag/2.19.2</p>"},{"location":"readme_cp/#image-ocr-support","title":"Image OCR support","text":"<p>Pydoxtools can automatically analyze images as well, makin use of OCR. In order to be able to use this, install tesseract on your system:</p> <p>Under linux this looks like the following:</p> <pre><code>apt-get update &amp;&amp; tesseract-ocr\n# install tesseract languages \n# Display a list of all Tesseract language packs:\n#   apt-cache search tesseract-ocr\n# install all languages:\n# sudo apt install tesseract-ocr-*\n# install only german, french, english, spanish language packs\n# sudo apt install tesseract-ocr-deu tesseract-ocr-fra tesseract-ocr-eng tesseract-ocr-spa\n</code></pre>"},{"location":"readme_cp/#development","title":"Development","text":"<p>--&gt; see </p>"},{"location":"readme_cp/#license","title":"License","text":"<p>This project is licensed under the terms of MIT license.</p> <p>You can check the compatibility using the following tool in a venv environment in a production setting:</p> <pre><code>pip install pip-licenses\npip-licenses | grep -Ev 'MIT License|BSD License|Apache Software License|Python Software Foundation License|Apache 2.0|MIT|Apache License 2.0|hnswlib|Pillow|new BSD|BSD'\n</code></pre>"},{"location":"readme_cp/#list-of-libraries-that-this-project-is-based-on","title":"list of libraries, that this project is based on:","text":"<p>list</p>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#pydoxtools.document.Document","title":"<code>Document</code>","text":"<p>         Bases: <code>Pipeline</code></p> <p>Basic document pipeline class to analyze documents from all kinds of formats.</p> <p>The Document class is designed for information extraction from documents. It inherits from the pydoxtools.document_base.Pipeline class and uses a predefined extraction pipeline f ocused on document processing tasks. To load a document, create an instance of the Document class with a file path, a file object, a string, a URL or give it some data directly as a dict:</p> <pre><code>from pydoxtools import Document\ndoc = Document(fobj=Path('./data/demo.docx'))\n</code></pre> <p>Extracted data can be accessed by calling the <code>x</code> method with the specified output in the pipeline:</p> <pre><code>doc.x(\"addresses\")\ndoc.x(\"entities\")\ndoc.x(\"full_text\")\n# etc...\n</code></pre> <p>Most members can also be called as normal class attributes for easier readability:</p> <pre><code>doc.addresses\n</code></pre> <p>Additionally, it is possible to get the data directly in dict, yaml or json form:</p> <pre><code>doc.property_dict(\"addresses\",\"filename\",\"keywords\")\ndoc.yaml(\"addresses\",\"filename\",\"keywords\")\ndoc.json(\"addresses\",\"filename\",\"keywords\")\n</code></pre> <p>To retrieve a list of all available extraction data methods, call the <code>x_funcs()</code> method:</p> <pre><code>doc.x_funcs()\n</code></pre>"},{"location":"reference/#pydoxtools.document.Document--customizing-the-pipeline","title":"Customizing the Pipeline:","text":"<p>The extraction pipeline can be partially overwritten or completely replaced to customize the document processing. To customize the pipeline, it's recommended to use the basic document pipeline defined in <code>pydoxtools.Document</code> as a starting point and only overwrite parts as needed.</p> <p>Inherited classes can override any part of the graph. To exchange, override, extend or introduce extraction pipelines for specific file types (including the generic one: \"\"), such as .html, .pdf, .txt, etc., follow the example below.</p> <p>TODO: provide more information on how to customize the pipeline and override the graph.</p>"},{"location":"reference/#pydoxtools.document.Document--examples","title":"Examples","text":"<p>The following is an example extension pipeline for an OCR extractor that converts images into text and supports file types: \".png\", \".jpeg\", \".jpg\", \".tif\", \".tiff\":</p> <pre><code>\"image\": [\n        OCRExtractor()\n        .pipe(file=\"raw_content\")\n        .out(\"ocr_pdf_file\")\n        .cache(),\n    ],\n\".png\": [\"image\", \".pdf\"],\n\".jpeg\": [\"image\", \".pdf\"],\n\".jpg\": [\"image\", \".pdf\"],\n\".tif\": [\"image\", \".pdf\"],\n\".tiff\": [\"image\", \".pdf\"],\n\"*\": [...]\n</code></pre> <p>Each function (or node) in the extraction pipeline connects to other nodes in the pipeline through the \"pipe\" command. Arguments can be overwritten by a new pipeline in inherited documents or document types higher up in the hierarchy. The argument precedence is as follows:</p> <pre><code>python-class-member &lt; extractor-graph-function &lt; configuration\n</code></pre> <p>When creating a new pipeline for documentation purposes, use a function or class for complex operations and include the documentation there. Lambda functions should not be used in this case.</p>"},{"location":"reference/#pydoxtools.document.Document.document_type","title":"<code>document_type</code>  <code>property</code> <code>cached</code>","text":"<p>detect doc type based on file-ending TODO add a doc-type extractor using for example python-magic</p>"},{"location":"reference/#pydoxtools.document.Document.filename","title":"<code>filename: str | None</code>  <code>property</code> <code>cached</code>","text":"<p>TODO: move this into document pipeline</p>"},{"location":"reference/#pydoxtools.document.Document.__init__","title":"<code>__init__(fobj=None, source=None, page_numbers=None, max_pages=None, mime_type=None, filename=None, document_type=None)</code>","text":"<p>Initialize a Document instance.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | Path</code> <p>The source of the extracted data (e.g., URL, 'pdfupload', parent-URL, or a path).</p> <code>None</code> <code>page_numbers</code> <code>list[int]</code> <p>A list of specific pages to extract from the document (e.g., in a PDF).</p> <code>None</code> <code>max_pages</code> <code>int</code> <p>The maximum number of pages to extract to protect resources.</p> <code>None</code> <code>mime_type</code> <code>str</code> <p>The MIME type of the document, if available.</p> <code>None</code> <code>filename</code> <code>str</code> <p>The filename of the document, which can sometimes help in determining its purpose.</p> <code>None</code> <code>document_type</code> <code>str</code> <p>The document type to directly specify the extraction logic to be used.</p> <code>None</code>"},{"location":"reference/#pydoxtools.document_base.Pipeline","title":"<code>Pipeline</code>","text":"<p>This class is the base for all document classes in pydoxtools and defines a common pipeline interface for all.</p> <p>This class also defines a basic extraction schema which derived classes can override</p> <p>in order to create a new pipeline, the _extractor variable shoud be overwritten with a pipeline definition</p> <p>this pipeline will get compiled in a function mappint defined in _x_funcs</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.configuration","title":"<code>configuration</code>  <code>property</code>","text":"<p>Get all configuration objects of our pipeline and merge them into a dict.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.x_funcs","title":"<code>x_funcs: dict[str, operators.Operator]</code>  <code>property</code> <code>cached</code>","text":"<p>get all extractors and their property names for this specific file type</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.__getattr__","title":"<code>__getattr__(extract_name)</code>","text":"<p>getattr only gets called for non-existing variable names. So we can automatically avoid name collisions  here.</p> <p>document.addresses</p> <p>instead of document.x['addresses']</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.config","title":"<code>config(**settings)</code>","text":"<p>Set configuration parameters for a pipeline</p> <p>This function loops through all \"operators.Configure\" and assigns the configuration from **settings to them.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.json","title":"<code>json(*args, **kwargs)</code>","text":"<p>same as property_dict, but dumps output as yaml</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.non_interactive_x_funcs","title":"<code>non_interactive_x_funcs()</code>","text":"<p>return all non-interactive extractors</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.pipeline_graph","title":"<code>pipeline_graph(image_path=None, document_logic_id='current')</code>","text":"<p>Generate a visualization of the defined pipelines</p> <p>image_path:  file path for a generated image</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.pre_cache","title":"<code>pre_cache()</code>","text":"<p>in some situations, for example for caching purposes it would be nice to pre-cache all calculations this is done here by simply calling all functions...</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.property_dict","title":"<code>property_dict(*args, **kwargs)</code>","text":"<p>return a dictionary which accumulates the properties given in args or with a mapping in *kwargs where the keys in kwargs are the variable in the returned dictionary, whereas the values are the variable names of the pipeline.</p> <p>Right now, this only works for properties that don#t need any arguments, in pipelines such as \"full_text\". Others, such as \"answers\" return a function which needs arguments itself and can therefore not be used here.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.run_all_extractors","title":"<code>run_all_extractors()</code>","text":"<p>can be used for testing or pre-caching purposes</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.x","title":"<code>x(extract_name, *args, **kwargs)</code>","text":"<p>call an extractor from our definition TODO: using args and *kwargs the extractors parameters can be overriden</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.yaml","title":"<code>yaml(*args, **kwargs)</code>","text":"<p>same as property_dict, but dumps output as yaml</p>"},{"location":"reference/#pydoxtools.operators","title":"<code>pydoxtools.operators</code>","text":"<p>The pydoxtools.operators module defines a set of generic pipeline operators that can be used inside of a pipeline class definition to create your own pipelines.</p>"},{"location":"reference/#pydoxtools.operators.Alias","title":"<code>Alias</code>","text":"<p>         Bases: <code>Operator</code></p> <p>Connect extractor variables with Aliases</p>"},{"location":"reference/#pydoxtools.operators.Configuration","title":"<code>Configuration</code>","text":"<p>         Bases: <code>Operator</code></p> <p>This is a special operator which can be used to configure a pipeline.</p> <p>Declare some configuration values which can then be used as inputs for other operators.</p> <p>It takes a list of key-value pairs where the key is the target variable name and the value is the standard configuration value.</p> <p>All \"Configuration\" values can be changed through the \"config\" function in a pipeline.</p> <p>When using a Configuration, we do not need an \"out\" mapping, as it will directly be mapped on the configuration keys. We can optionally do this though.</p> <p>The Question &amp; Answering part of the pydoxtools.Document class</p> was specified with this config function like this <p>QamExtractor(model_id=settings.PDXT_STANDARD_QAM_MODEL)     .pipe(text=\"full_text\").out(\"answers\").cache().config(trf_model_id=\"qam_model_id\"),</p> <p>In this case, when calling a document we can dynamically configure the pipeline with the \"qam_model_id\" parameter:</p> <pre><code>doc = Document(\n    fobj=doc_str, document_type=\".pdf\"\n).config(dict(qam_model_id='deepset/roberta-base-squad2'))\n</code></pre>"},{"location":"reference/#pydoxtools.operators.Constant","title":"<code>Constant</code>","text":"<p>         Bases: <code>Operator</code></p> <p>declare one ore more constant values</p>"},{"location":"reference/#pydoxtools.operators.ElementWiseOperator","title":"<code>ElementWiseOperator</code>","text":"<p>         Bases: <code>Operator</code></p> <p>Take a function and apply it elementwise to an iterable. Return a list or iterator.</p> <p>the \"elements\" argument will be evaluated element-wise. You can specify additional arguments for the function using args and *kwargs.</p>"},{"location":"reference/#pydoxtools.operators.LambdaOperator","title":"<code>LambdaOperator</code>","text":"<p>         Bases: <code>Operator</code></p> <p>Wrap an arbitrary function as an Operator</p>"},{"location":"reference/#pydoxtools.operators.Operator","title":"<code>Operator</code>","text":"<p>         Bases: <code>ABC</code></p> <p>Base class to build extraction logic for information extraction from unstructured documents and loading files</p> <p>Extractors should always be stateless! This means one should not save any variables in them that persist over the lifecycle over a single extraction operation.</p> <ul> <li>Extractors can be \"hooked\" into the document pipeline by using:     pipe, out and cache calls.</li> <li>all parameters given in \"out\" can be accessed through the \"x\" property   (e.g. doc.x(\"extraction_parameter\"))</li> </ul> <p>dynamic configuration of an extractor parameters can be configured through \"config\" function which will indicate to the parent document class to set some input parameters to this function manually. If the same parameters are also set in doc.pipe the parameters are optional and will only be taken if explicitly set through doc.config(...).</p> <pre><code>doc.dynamic()\n</code></pre> <p>This function can be accessed through:</p> <pre><code>doc.config(my_dynamic_parameter=\"some_new_value\")\n</code></pre>"},{"location":"reference/#pydoxtools.operators.Operator.cache","title":"<code>cache()</code>","text":"<p>indicate to document that we want this extractor function to be cached</p>"},{"location":"reference/#pydoxtools.operators.Operator.out","title":"<code>out(*args, **kwargs)</code>","text":"<p>configure output parameter mappings to this function</p> <p>keys: are the</p>"},{"location":"reference/#pydoxtools.operators.Operator.pipe","title":"<code>pipe(*args, **kwargs)</code>","text":"<p>configure input parameter mappings to this function</p> <p>keys: are the actual function parameters of the extractor function values: are the outside function names</p>"}]}