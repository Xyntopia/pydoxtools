{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Pydoxtools Documentation!","text":"<p>For a short overview over Pydoxtools, checkout the readme on the project page:</p> <p>Readme</p>"},{"location":"#introduction","title":"Introduction","text":"<p>Pydoxtools provides a user-friendly interface for document analysis and  manipulation, consisting of three main classes:</p> <ul> <li>pydoxtools.Document</li> <li>pydoxtools.DocumentBag</li> <li>pydoxtools.Pipeline</li> </ul> <p>Additionally, it offers a collection of operators:</p> <ul> <li>pydoxtools.operators</li> </ul>"},{"location":"#analyzing-documents","title":"Analyzing Documents","text":"<p>Both, Document and DocumentBag utilize pydoxtools.Pipeline to define a  sophisticated pipeline for extracting data from individual or multiple documents.  You can find a list of all the built-in features for each pipeline here:</p> <p>-&gt; pydoxtools.Document and pydoxtools.DocumentBag </p> <p>To ensure seamless operation, Pydoxtools is designed so that  Document and DocumentSet  automatically organize information in a logical manner while minimizing  memory and CPU usage. This approach makes the library highly compatible  with AI and LLMs in automated settings. As a result, it is not possible  to configure how documents are loaded using configuration parameters.  However, you can easily achieve specific data organization by chaining documents together.</p> <p>TODO:  provide an example</p>"},{"location":"#building-custom-pipelines-with-llms-large-language-models-and-other-ai-tools","title":"Building Custom Pipelines with LLMs (Large Language Models) and other AI Tools","text":"<p>The Pipeline class allows you to create complex, custom pipelines that come with several built-in features, making them easy to integrate with modern AI tools:</p> <ul> <li>Mix, extend, or (partially) overwrite pipelines</li> <li>Export/import data (yaml, json, python-dict)</li> <li>Configure and optimize pipelines</li> <li>Convert data into pydoxtools.Document and pydoxtools.DocumentBag</li> </ul> <p>To develop a custom pipeline, you can utilize the extensive library of pydoxtools.operators. It is generally recommended to use  pydoxtools.Document or pydoxtools.DocumentBag as a base for  a new pipeline and only replace small parts to achieve the desired  custom functionality.</p>"},{"location":"#visualizing-pipelines","title":"Visualizing Pipelines","text":"<p>Visualizing pipelines can be incredibly helpful when developing your  own pipeline on top of a complex one, such as the document pipeline.  You can visualize the extraction logic for different file types from the Document class (which is a pydoxtools.Pipeline  itself) as follows:</p> <pre><code>doc = Document(fobj=make_path_absolute(\"./data/demo.docx\"))\n# for the currently loaded file type:\ndoc.logic_graph(image_path=settings._PYDOXTOOLS_DIR / \"docs/images/document_logic_docx.svg\")\n# for the \ndoc.logic_graph(image_path=settings._PYDOXTOOLS_DIR / \"docs/images/document_logic_png.svg\", document_logic_id=\".png\")\n</code></pre> <p>This allows you to generate pipelines for various file types:</p> <ul> <li>docx</li> <li>png   (click on links to open the images!)</li> </ul> <p>You can find pipelines for every supported file type  here.</p> <p>This feature is also available for custom pipelines!</p> <p>To learn more, continue to: Reference</p>"},{"location":"DEVELOPMENT/","title":"Development &amp; Contribution","text":"<p>The graph model of the library makes it very easy to extend it with new functionality.</p> <ul> <li>the document can be used as a base-model and overwritten with changes</li> <li>the graph can be changed dynamically</li> <li>new functions can be very easily integrated</li> </ul>"},{"location":"DEVELOPMENT/#installation-from-other-branches","title":"Installation from other branches","text":"<p>In order to install pydoxtools from a development branch \"development_branch\" you can do this:</p> <p>pip install -U \"pydoxtools[etl,inference] @ git+https://github.com/xyntopia/pydoxtools.git@development_branch\"</p>"},{"location":"DEVELOPMENT/#pydoxtools-architecture","title":"Pydoxtools Architecture","text":"<p>--&gt; refer to \"document\"</p>"},{"location":"DEVELOPMENT/#contribution-guidelines","title":"Contribution Guidelines","text":""},{"location":"document/","title":"pydoxtools.Document","text":"<p>         Bases: <code>Pipeline</code></p> <p>Basic document pipeline class to analyze documents from all kinds of formats.</p> <p>A list and documentation of all document analysis related functions can be found -&gt;here&lt;-.</p> <p>The Document class is designed for information extraction from documents. It inherits from the pydoxtools.document_base.Pipeline class and uses a predefined extraction pipeline focused on document processing tasks. To load a document, create an instance of the Document class with a file path, a file object, a string, a URL or give it some data directly as a dict:</p> <pre><code>from pydoxtools import Document\ndoc = Document(fobj=Path('./data/demo.docx'))\n</code></pre> <p>Extracted data can be accessed by calling the <code>x</code> method with the specified output in the pipeline:</p> <pre><code>doc.x(\"addresses\")\ndoc.x(\"entities\")\ndoc.x(\"full_text\")\n# etc...\n</code></pre> <p>Most members can also be called as normal class attributes for easier readability:</p> <pre><code>doc.addresses\n</code></pre> <p>Additionally, it is possible to get the data directly in dict, yaml or json form:</p> <pre><code>doc.property_dict(\"addresses\",\"filename\",\"keywords\")\ndoc.yaml(\"addresses\",\"filename\",\"keywords\")\ndoc.json(\"addresses\",\"filename\",\"keywords\")\n</code></pre> <p>To retrieve a list of all available extraction data methods, call the <code>x_funcs()</code> method:</p> <pre><code>doc.x_funcs()\n</code></pre>"},{"location":"document/#pydoxtools.Document--customizing-the-pipeline","title":"Customizing the Pipeline:","text":"<p>The extraction pipeline can be partially overwritten or completely replaced to customize the document processing. To customize the pipeline, it's recommended to use the basic document pipeline defined in <code>pydoxtools.Document</code> as a starting point and only overwrite parts as needed.</p> <p>Inherited classes can override any part of the graph. To exchange, override, extend or introduce extraction pipelines for specific file types (including the generic one: \"\"), such as .html, .pdf, .txt, etc., follow the example below.</p> <p>TODO: provide more information on how to customize the pipeline and override the graph.</p>"},{"location":"document/#pydoxtools.Document--examples","title":"Examples","text":"<p>The following is an example extension pipeline for an OCR extractor that converts images into text and supports file types: \".png\", \".jpeg\", \".jpg\", \".tif\", \".tiff\":</p> <pre><code>\"image\": [\n        OCRExtractor()\n        .pipe(file=\"raw_content\")\n        .out(\"ocr_pdf_file\")\n        .cache(),\n    ],\n\".png\": [\"image\", \".pdf\"],\n\".jpeg\": [\"image\", \".pdf\"],\n\".jpg\": [\"image\", \".pdf\"],\n\".tif\": [\"image\", \".pdf\"],\n\".tiff\": [\"image\", \".pdf\"],\n\"*\": [...]\n</code></pre> <p>Each function (or node) in the extraction pipeline connects to other nodes in the pipeline through the \"pipe\" command. Arguments can be overwritten by a new pipeline in inherited documents or document types higher up in the hierarchy. The argument precedence is as follows:</p> <pre><code>python-class-member &lt; extractor-graph-function &lt; configuration\n</code></pre> <p>When creating a new pipeline for documentation purposes, use a function or class for complex operations and include the documentation there. Lambda functions should not be used in this case.</p>"},{"location":"document/#pydoxtools.document.Document.document_type","title":"<code>document_type</code>  <code>property</code>","text":"<p>This has to be done in a member function and not in the pipeline, because the selection of the pipeline depends on this...</p>"},{"location":"document/#pydoxtools.document.Document.filename","title":"<code>filename: str | None</code>  <code>property</code>","text":"<p>return filename or some other identifier of a file</p>"},{"location":"document/#pydoxtools.document.Document.__init__","title":"<code>__init__(fobj=None, source=None, meta=None, document_type='auto', page_numbers=None, max_pages=None)</code>","text":"<p>Initialize a Document instance.</p> <p>Either fobj or source are required. They can both be given. If either of them isn't specified the other one is inferred automatically.</p> <p>document_type, page_number and max_pages are also not required, but can be used to override the default behaviour. specifically document_type can be used manually specify the pipeline that should be used.</p> <p>Parameters:</p> Name Type Description Default <code>fobj</code> <code>str | bytes | Path | IO | dict | list | set</code> <p>The file object or data to load. Depending on the type of object passed: - If a string or bytes object: the object itself is the document. IN case of a bytes      object, the source helps in determining the filetype through file endings. - If a string representing a URL: the document will be loaded from the URL. - If a pathlib.Path object: load the document from the path. - If a file object: load the document from the file object (e.g., bytestream). - If a python dict object: interprete a \"dict\" as a document - If a python list object: interprete a \"list\" as a document</p> <code>None</code> <code>source</code> <code>str | Path</code> <p>The source of the extracted data (e.g., URL, 'pdfupload', parent-URL, or a path). source is given in addition to fobj it overrides the automatically inferred source. A special case applies if our document is a dataobject from a database. In that case the index key from the database should be used as source. This facilitates downstream tasks immensely where we have to refer back to where the data came from.</p> <p>This also applies for \"explode\" operations on documents where the newly created documents will all try to trace their origin using the \"source\" attribute</p> <code>None</code> <code>document_type</code> <code>str</code> <p>The document type to directly specify the pipeline to be used. If \"auto\" is given it will try to be inferred automatically. For example in some cases we would like to have a string given in fobj not to be loaded as a file but actually be used as raw \"string\" data. In this case we can explicitly specify document_type=\"string\"</p> <code>'auto'</code> <code>meta</code> <code>dict[str, str]</code> <p>Optionally set document metadata, which can be very useful for downstream tasks like building an index.</p> <code>None</code> <code>page_numbers</code> <code>list[int]</code> <p>A list of specific pages to extract from the document (e.g., in a PDF).</p> <code>None</code> <code>max_pages</code> <code>int</code> <p>The maximum number of pages to extract to protect resources.</p> <code>None</code>"},{"location":"document/#pydoxtools.document.Document.__repr__","title":"<code>__repr__()</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>A string representation of the instance.</p>"},{"location":"document/#pydoxtools.document.Document.document_type_detection","title":"<code>document_type_detection()</code>  <code>cached</code>","text":"<p>This one here is actually important as it detects the type of data that we are going to use for out pipeline. That is also why this is implemented as a member function and can not be pushed in the pipeline itself, because in needs to be run in order to select which pipline we are going to use.</p> <p>detect doc type based on various criteria TODO add a doc-type extractor using for example python-magic</p>"},{"location":"document/#text-extraction-attributes-and-functions","title":"Text extraction attributes and functions","text":"<p>The pydoxtools.Document is built on the pydoxtools.Pipeline class and most of the text extraction functionality makes extensive use of the pipeline features. All attributes and functions that are created by the pipeline are documented here.</p> <p>Pipeline visualizations for the structure of the Document pipelines for different document types can be found here.</p>"},{"location":"document/#raw_content","title":"raw_content","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('raw_content')\n# or\n&lt;Document&gt;.raw_content\n</code></pre> <p>return type : bytes | str</p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#data","title":"data","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('data')\n# or\n&lt;Document&gt;.data\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#full_text","title":"full_text","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('full_text')\n# or\n&lt;Document&gt;.full_text\n</code></pre> <p>return type :  <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#clean_text","title":"clean_text","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('clean_text')\n# or\n&lt;Document&gt;.clean_text\n</code></pre> <p>return type :  <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#meta","title":"meta","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('meta')\n# or\n&lt;Document&gt;.meta\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#file_meta","title":"file_meta","text":"<p>some fast-to-calculate metadata information about a file</p> <p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('file_meta')\n# or\n&lt;Document&gt;.file_meta\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#text_box_elements","title":"text_box_elements","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('text_box_elements')\n# or\n&lt;Document&gt;.text_box_elements\n</code></pre> <p>return type :  <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#text_box_list","title":"text_box_list","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('text_box_list')\n# or\n&lt;Document&gt;.text_box_list\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#tables_df","title":"tables_df","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('tables_df')\n# or\n&lt;Document&gt;.tables_df\n</code></pre> <p>return type : str | list[str] | list[pandas.core.frame.DataFrame]</p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#tables_dict","title":"tables_dict","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('tables_dict')\n# or\n&lt;Document&gt;.tables_dict\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#tables","title":"tables","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('tables')\n# or\n&lt;Document&gt;.tables\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#addresses","title":"addresses","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('addresses')\n# or\n&lt;Document&gt;.addresses\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#num_pages","title":"num_pages","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('num_pages')\n# or\n&lt;Document&gt;.num_pages\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#num_words","title":"num_words","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('num_words')\n# or\n&lt;Document&gt;.num_words\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#num_sents","title":"num_sents","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('num_sents')\n# or\n&lt;Document&gt;.num_sents\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#a_d_ratio","title":"a_d_ratio","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('a_d_ratio')\n# or\n&lt;Document&gt;.a_d_ratio\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#language","title":"language","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('language')\n# or\n&lt;Document&gt;.language\n</code></pre> <p>return type :  <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#spacy_model_size","title":"spacy_model_size","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('spacy_model_size')\n# or\n&lt;Document&gt;.spacy_model_size\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#spacy_model","title":"spacy_model","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('spacy_model')\n# or\n&lt;Document&gt;.spacy_model\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#spacy_doc","title":"spacy_doc","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('spacy_doc')\n# or\n&lt;Document&gt;.spacy_doc\n</code></pre> <p>return type : dict[str, typing.Any]</p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#spacy_nlp","title":"spacy_nlp","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('spacy_nlp')\n# or\n&lt;Document&gt;.spacy_nlp\n</code></pre> <p>return type : dict[str, typing.Any]</p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#spacy_vectors","title":"spacy_vectors","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('spacy_vectors')\n# or\n&lt;Document&gt;.spacy_vectors\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#spacy_embeddings","title":"spacy_embeddings","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('spacy_embeddings')\n# or\n&lt;Document&gt;.spacy_embeddings\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#spacy_sents","title":"spacy_sents","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('spacy_sents')\n# or\n&lt;Document&gt;.spacy_sents\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#spacy_noun_chunks","title":"spacy_noun_chunks","text":"<p>exracts nounchunks from spacy. Will not be cached because it is allin the spacy doc already</p> <p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('spacy_noun_chunks')\n# or\n&lt;Document&gt;.spacy_noun_chunks\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#entities","title":"entities","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('entities')\n# or\n&lt;Document&gt;.entities\n</code></pre> <p>return type : dict[str, list[str]]</p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#url","title":"url","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('url')\n# or\n&lt;Document&gt;.url\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#sents","title":"sents","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('sents')\n# or\n&lt;Document&gt;.sents\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#noun_chunks","title":"noun_chunks","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('noun_chunks')\n# or\n&lt;Document&gt;.noun_chunks\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#vector","title":"vector","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('vector')\n# or\n&lt;Document&gt;.vector\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#sent_vecs","title":"sent_vecs","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('sent_vecs')\n# or\n&lt;Document&gt;.sent_vecs\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#sent_ids","title":"sent_ids","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('sent_ids')\n# or\n&lt;Document&gt;.sent_ids\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#noun_vecs","title":"noun_vecs","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('noun_vecs')\n# or\n&lt;Document&gt;.noun_vecs\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#noun_ids","title":"noun_ids","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('noun_ids')\n# or\n&lt;Document&gt;.noun_ids\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#vectorizer_model","title":"vectorizer_model","text":"<p>Choose the embeddings model (huggingface-style) and if we wantto do the vectorization using only the tokenizer. Using only thetokenizer is MUCH faster and uses lower CPU than creating actualcontextual embeddings using the model. BUt is also lower qualitybecause it lacks the context.</p> <p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('vectorizer_model')\n# or\n&lt;Document&gt;.vectorizer_model\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#vectorizer_only_tokenizer","title":"vectorizer_only_tokenizer","text":"<p>Choose the embeddings model (huggingface-style) and if we wantto do the vectorization using only the tokenizer. Using only thetokenizer is MUCH faster and uses lower CPU than creating actualcontextual embeddings using the model. BUt is also lower qualitybecause it lacks the context.</p> <p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('vectorizer_only_tokenizer')\n# or\n&lt;Document&gt;.vectorizer_only_tokenizer\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#vectorizer_overlap_ratio","title":"vectorizer_overlap_ratio","text":"<p>Choose the embeddings model (huggingface-style) and if we wantto do the vectorization using only the tokenizer. Using only thetokenizer is MUCH faster and uses lower CPU than creating actualcontextual embeddings using the model. BUt is also lower qualitybecause it lacks the context.</p> <p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('vectorizer_overlap_ratio')\n# or\n&lt;Document&gt;.vectorizer_overlap_ratio\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#vec_res","title":"vec_res","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('vec_res')\n# or\n&lt;Document&gt;.vec_res\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#tok_embeddings","title":"tok_embeddings","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('tok_embeddings')\n# or\n&lt;Document&gt;.tok_embeddings\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#tokens","title":"tokens","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('tokens')\n# or\n&lt;Document&gt;.tokens\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#embedding","title":"embedding","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('embedding')\n# or\n&lt;Document&gt;.embedding\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#min_size_text_segment","title":"min_size_text_segment","text":"<p>controls the text segmentation for knowledge basesoverlap is only relevant for large text segmenets that need tobe split up into smaller pieces.</p> <p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('min_size_text_segment')\n# or\n&lt;Document&gt;.min_size_text_segment\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#max_size_text_segment","title":"max_size_text_segment","text":"<p>controls the text segmentation for knowledge basesoverlap is only relevant for large text segmenets that need tobe split up into smaller pieces.</p> <p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('max_size_text_segment')\n# or\n&lt;Document&gt;.max_size_text_segment\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#text_segment_overlap","title":"text_segment_overlap","text":"<p>controls the text segmentation for knowledge basesoverlap is only relevant for large text segmenets that need tobe split up into smaller pieces.</p> <p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('text_segment_overlap')\n# or\n&lt;Document&gt;.text_segment_overlap\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#text_segments","title":"text_segments","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('text_segments')\n# or\n&lt;Document&gt;.text_segments\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#text_segment_vectors","title":"text_segment_vectors","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('text_segment_vectors')\n# or\n&lt;Document&gt;.text_segment_vectors\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#noun_index","title":"noun_index","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('noun_index')\n# or\n&lt;Document&gt;.noun_index\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#vectorizer","title":"vectorizer","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('vectorizer')\n# or\n&lt;Document&gt;.vectorizer\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#noun_query","title":"noun_query","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('noun_query')\n# or\n&lt;Document&gt;.noun_query\n</code></pre> <p>return type : typing.Callable</p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#noun_graph","title":"noun_graph","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('noun_graph')\n# or\n&lt;Document&gt;.noun_graph\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#top_k_text_rank_keywords","title":"top_k_text_rank_keywords","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('top_k_text_rank_keywords')\n# or\n&lt;Document&gt;.top_k_text_rank_keywords\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#textrank_keywords","title":"textrank_keywords","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('textrank_keywords')\n# or\n&lt;Document&gt;.textrank_keywords\n</code></pre> <p>return type : set[str]</p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#keywords","title":"keywords","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('keywords')\n# or\n&lt;Document&gt;.keywords\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#sent_index","title":"sent_index","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('sent_index')\n# or\n&lt;Document&gt;.sent_index\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#sent_query","title":"sent_query","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('sent_query')\n# or\n&lt;Document&gt;.sent_query\n</code></pre> <p>return type : typing.Callable</p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#sent_graph","title":"sent_graph","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('sent_graph')\n# or\n&lt;Document&gt;.sent_graph\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#top_k_text_rank_sentences","title":"top_k_text_rank_sentences","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('top_k_text_rank_sentences')\n# or\n&lt;Document&gt;.top_k_text_rank_sentences\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#textrank_sents","title":"textrank_sents","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('textrank_sents')\n# or\n&lt;Document&gt;.textrank_sents\n</code></pre> <p>return type : set[str]</p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#summarizer_model","title":"summarizer_model","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('summarizer_model')\n# or\n&lt;Document&gt;.summarizer_model\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#summarizer_token_overlap","title":"summarizer_token_overlap","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('summarizer_token_overlap')\n# or\n&lt;Document&gt;.summarizer_token_overlap\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#summarizer_max_text_len","title":"summarizer_max_text_len","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('summarizer_max_text_len')\n# or\n&lt;Document&gt;.summarizer_max_text_len\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#slow_summary","title":"slow_summary","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('slow_summary')\n# or\n&lt;Document&gt;.slow_summary\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#qam_model_id","title":"qam_model_id","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('qam_model_id')\n# or\n&lt;Document&gt;.qam_model_id\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#answers","title":"answers","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('answers')\n# or\n&lt;Document&gt;.answers\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#openai_chat_model_id","title":"openai_chat_model_id","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('openai_chat_model_id')\n# or\n&lt;Document&gt;.openai_chat_model_id\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#chat_answers","title":"chat_answers","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('chat_answers')\n# or\n&lt;Document&gt;.chat_answers\n</code></pre> <p>return type : typing.Callable[[list[str], list[str] | str], list[str]]</p> <p>supports pipelines : *,,,application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,application/x-yaml,image,image/jpeg,image/png,image/tiff,pandoc,text/html,text/markdown,text/rtf"},{"location":"document/#meta_pdf","title":"meta_pdf","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('meta_pdf')\n# or\n&lt;Document&gt;.meta_pdf\n</code></pre> <p>return type : </p> <p>supports pipelines : application/pdf,image,image/jpeg,image/png,image/tiff</p>"},{"location":"document/#page_set","title":"page_set","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('page_set')\n# or\n&lt;Document&gt;.page_set\n</code></pre> <p>return type : </p> <p>supports pipelines : application/pdf,image,image/jpeg,image/png,image/tiff</p>"},{"location":"document/#pages_bbox","title":"pages_bbox","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('pages_bbox')\n# or\n&lt;Document&gt;.pages_bbox\n</code></pre> <p>return type : </p> <p>supports pipelines : application/pdf,image,image/jpeg,image/png,image/tiff</p>"},{"location":"document/#elements","title":"elements","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('elements')\n# or\n&lt;Document&gt;.elements\n</code></pre> <p>return type : </p> <p>supports pipelines : application/pdf,image,image/jpeg,image/png,image/tiff</p>"},{"location":"document/#line_elements","title":"line_elements","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('line_elements')\n# or\n&lt;Document&gt;.line_elements\n</code></pre> <p>return type : </p> <p>supports pipelines : application/pdf,image,image/jpeg,image/png,image/tiff</p>"},{"location":"document/#graphic_elements","title":"graphic_elements","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('graphic_elements')\n# or\n&lt;Document&gt;.graphic_elements\n</code></pre> <p>return type : </p> <p>supports pipelines : application/pdf,image,image/jpeg,image/png,image/tiff</p>"},{"location":"document/#lists","title":"lists","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('lists')\n# or\n&lt;Document&gt;.lists\n</code></pre> <p>return type : str | list[str] | list[pandas.core.frame.DataFrame]</p> <p>supports pipelines : application/epub+zip,application/pdf,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,image,image/jpeg,image/png,image/tiff,pandoc,text/markdown,text/rtf</p>"},{"location":"document/#table_box_levels","title":"table_box_levels","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('table_box_levels')\n# or\n&lt;Document&gt;.table_box_levels\n</code></pre> <p>return type : </p> <p>supports pipelines : application/pdf,image,image/jpeg,image/png,image/tiff</p>"},{"location":"document/#table_candidates","title":"table_candidates","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('table_candidates')\n# or\n&lt;Document&gt;.table_candidates\n</code></pre> <p>return type : </p> <p>supports pipelines : application/pdf,image,image/jpeg,image/png,image/tiff</p>"},{"location":"document/#table_df0","title":"table_df0","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('table_df0')\n# or\n&lt;Document&gt;.table_df0\n</code></pre> <p>return type : </p> <p>supports pipelines : application/pdf,image,image/jpeg,image/png,image/tiff</p>"},{"location":"document/#titles","title":"titles","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('titles')\n# or\n&lt;Document&gt;.titles\n</code></pre> <p>return type : </p> <p>supports pipelines : application/pdf,image,image/jpeg,image/png,image/tiff,text/html</p>"},{"location":"document/#side_titles","title":"side_titles","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('side_titles')\n# or\n&lt;Document&gt;.side_titles\n</code></pre> <p>return type : </p> <p>supports pipelines : application/pdf,image,image/jpeg,image/png,image/tiff</p>"},{"location":"document/#html_keywords_str","title":"html_keywords_str","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('html_keywords_str')\n# or\n&lt;Document&gt;.html_keywords_str\n</code></pre> <p>return type : </p> <p>supports pipelines : text/html</p>"},{"location":"document/#main_content_clean_html","title":"main_content_clean_html","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('main_content_clean_html')\n# or\n&lt;Document&gt;.main_content_clean_html\n</code></pre> <p>return type : </p> <p>supports pipelines : text/html</p>"},{"location":"document/#summary","title":"summary","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('summary')\n# or\n&lt;Document&gt;.summary\n</code></pre> <p>return type : </p> <p>supports pipelines : text/html</p>"},{"location":"document/#goose_article","title":"goose_article","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('goose_article')\n# or\n&lt;Document&gt;.goose_article\n</code></pre> <p>return type : </p> <p>supports pipelines : text/html</p>"},{"location":"document/#main_content","title":"main_content","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('main_content')\n# or\n&lt;Document&gt;.main_content\n</code></pre> <p>return type : </p> <p>supports pipelines : text/html</p>"},{"location":"document/#schemadata","title":"schemadata","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('schemadata')\n# or\n&lt;Document&gt;.schemadata\n</code></pre> <p>return type : </p> <p>supports pipelines : text/html</p>"},{"location":"document/#final_urls","title":"final_urls","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('final_urls')\n# or\n&lt;Document&gt;.final_urls\n</code></pre> <p>return type : </p> <p>supports pipelines : text/html</p>"},{"location":"document/#pdf_links","title":"pdf_links","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('pdf_links')\n# or\n&lt;Document&gt;.pdf_links\n</code></pre> <p>return type : </p> <p>supports pipelines : text/html</p>"},{"location":"document/#title","title":"title","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('title')\n# or\n&lt;Document&gt;.title\n</code></pre> <p>return type : </p> <p>supports pipelines : text/html</p>"},{"location":"document/#short_title","title":"short_title","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('short_title')\n# or\n&lt;Document&gt;.short_title\n</code></pre> <p>return type : </p> <p>supports pipelines : text/html</p>"},{"location":"document/#urls","title":"urls","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('urls')\n# or\n&lt;Document&gt;.urls\n</code></pre> <p>return type : </p> <p>supports pipelines : text/html</p>"},{"location":"document/#main_image","title":"main_image","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('main_image')\n# or\n&lt;Document&gt;.main_image\n</code></pre> <p>return type : </p> <p>supports pipelines : text/html</p>"},{"location":"document/#html_keywords","title":"html_keywords","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('html_keywords')\n# or\n&lt;Document&gt;.html_keywords\n</code></pre> <p>return type : </p> <p>supports pipelines : text/html</p>"},{"location":"document/#pandoc_document","title":"pandoc_document","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('pandoc_document')\n# or\n&lt;Document&gt;.pandoc_document\n</code></pre> <p>return type : Pandoc(Meta, [Block])</p> <p>supports pipelines : application/epub+zip,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,pandoc,text/markdown,text/rtf</p>"},{"location":"document/#full_text_format","title":"full_text_format","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('full_text_format')\n# or\n&lt;Document&gt;.full_text_format\n</code></pre> <p>return type : </p> <p>supports pipelines : application/epub+zip,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,pandoc,text/markdown,text/rtf</p>"},{"location":"document/#convert_to","title":"convert_to","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('convert_to')\n# or\n&lt;Document&gt;.convert_to\n</code></pre> <p>return type : </p> <p>supports pipelines : application/epub+zip,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,pandoc,text/markdown,text/rtf</p>"},{"location":"document/#clean_format","title":"clean_format","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('clean_format')\n# or\n&lt;Document&gt;.clean_format\n</code></pre> <p>return type : </p> <p>supports pipelines : application/epub+zip,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,pandoc,text/markdown,text/rtf</p>"},{"location":"document/#sections","title":"sections","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('sections')\n# or\n&lt;Document&gt;.sections\n</code></pre> <p>return type : </p> <p>supports pipelines : application/epub+zip,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,pandoc,text/markdown,text/rtf</p>"},{"location":"document/#pandoc_blocks","title":"pandoc_blocks","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('pandoc_blocks')\n# or\n&lt;Document&gt;.pandoc_blocks\n</code></pre> <p>return type : list['pandoc.types.Block']</p> <p>supports pipelines : application/epub+zip,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,pandoc,text/markdown,text/rtf</p>"},{"location":"document/#headers","title":"headers","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('headers')\n# or\n&lt;Document&gt;.headers\n</code></pre> <p>return type : str | list[str] | list[pandas.core.frame.DataFrame]</p> <p>supports pipelines : application/epub+zip,application/vnd.oasis.opendocument.text,application/vnd.openxmlformats-officedocument.wordprocessingml.document,pandoc,text/markdown,text/rtf</p>"},{"location":"document/#ocr_lang","title":"ocr_lang","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('ocr_lang')\n# or\n&lt;Document&gt;.ocr_lang\n</code></pre> <p>return type : </p> <p>supports pipelines : image,image/jpeg,image/png,image/tiff</p>"},{"location":"document/#ocr_on","title":"ocr_on","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('ocr_on')\n# or\n&lt;Document&gt;.ocr_on\n</code></pre> <p>return type : </p> <p>supports pipelines : image,image/jpeg,image/png,image/tiff</p>"},{"location":"document/#ocr_pdf_file","title":"ocr_pdf_file","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('ocr_pdf_file')\n# or\n&lt;Document&gt;.ocr_pdf_file\n</code></pre> <p>return type : </p> <p>supports pipelines : image,image/jpeg,image/png,image/tiff</p>"},{"location":"document/#data_sel","title":"data_sel","text":"<p>select values by key from source data in Document</p> <p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('data_sel')\n# or\n&lt;Document&gt;.data_sel\n</code></pre> <p>return type : typing.Callable[..., dict]</p> <p>supports pipelines : ,application/x-yaml"},{"location":"document/#keys","title":"keys","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('keys')\n# or\n&lt;Document&gt;.keys\n</code></pre> <p>return type : </p> <p>supports pipelines : ,application/x-yaml"},{"location":"document/#values","title":"values","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('values')\n# or\n&lt;Document&gt;.values\n</code></pre> <p>return type : </p> <p>supports pipelines : ,application/x-yaml"},{"location":"document/#items","title":"items","text":"<p>Can be called using:</p> <pre><code>&lt;Document&gt;.x('items')\n# or\n&lt;Document&gt;.items\n</code></pre> <p>return type : </p> <p>supports pipelines : ,application/x-yaml"},{"location":"documentbag/","title":"pydoxtools.DocumentBag","text":"<p>         Bases: <code>Pipeline</code></p> <p>This class is a work-in-progress (WIP), use with caution.</p> <p>The DocumentBag class loads and processes a set of documents using a pipeline. It leverages Dask bags for efficient memory usage and large-scale computations on documents.</p> Notes <ul> <li>Dask bags documentation can be found here.</li> <li>Dask dataframes can be used for downstream calculations.</li> <li>This class helps scale LLM &amp; AI inference to larger workloads.</li> <li>It uses iterative Dask bags &amp; dataframes to avoid out-of-memory issues.</li> </ul> Rationale <p>This function is needed to create and process new document bags, instead of using Dask bags directly with arbitrary data. It reduces boilerplate code for creating new documents and traceable datasources.</p>"},{"location":"documentbag/#pydoxtools.document.DocumentBag.__repr__","title":"<code>__repr__()</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>A string representation of the instance.</p>"},{"location":"documentbag/#text-extraction-attributes-and-functions","title":"Text extraction attributes and functions","text":"<p>The pydoxtools.DocumentBag is built on the pydoxtools.Pipeline class and most of the text extraction functionality makes extensive use of the pipeline features. All attributes and functions that are created by the pipeline are documented here.</p> <p>Pipeline visualizations for the structure of the Document pipelines for different document types can be found here.</p>"},{"location":"documentbag/#doc_configuration","title":"doc_configuration","text":"<p>We can pass through a configuration object to Documents that are created in our document bag. Any setting that is supported by Document can be specified here.</p> <p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('doc_configuration')\n# or\n&lt;DocumentBag&gt;.doc_configuration\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,,"},{"location":"documentbag/#forgiving_extracts","title":"forgiving_extracts","text":"<p>When enabled, if we execute certain batch operations on our document bag, this will not stop the extraction, but rather put an error message in the document.</p> <p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('forgiving_extracts')\n# or\n&lt;DocumentBag&gt;.forgiving_extracts\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,,"},{"location":"documentbag/#_stats","title":"_stats","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('_stats')\n# or\n&lt;DocumentBag&gt;._stats\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,,"},{"location":"documentbag/#verbosity","title":"verbosity","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('verbosity')\n# or\n&lt;DocumentBag&gt;.verbosity\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,,"},{"location":"documentbag/#get_dicts","title":"get_dicts","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('get_dicts')\n# or\n&lt;DocumentBag&gt;.get_dicts\n</code></pre> <p>return type : typing.Callable[[typing.Any], dask.bag.core.Bag]</p> <p>supports pipelines : *,,,,"},{"location":"documentbag/#d","title":"d","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('d')\n# or\n&lt;DocumentBag&gt;.d\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,,"},{"location":"documentbag/#bag_apply","title":"bag_apply","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('bag_apply')\n# or\n&lt;DocumentBag&gt;.bag_apply\n</code></pre> <p>return type : typing.Callable[..., dask.bag.core.Bag]</p> <p>supports pipelines : *,,,,"},{"location":"documentbag/#apply","title":"apply","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('apply')\n# or\n&lt;DocumentBag&gt;.apply\n</code></pre> <p>return type : typing.Callable[..., pydoxtools.document.DocumentBag]</p> <p>supports pipelines : *,,,,"},{"location":"documentbag/#exploded","title":"exploded","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('exploded')\n# or\n&lt;DocumentBag&gt;.exploded\n</code></pre> <p>return type : typing.Callable[..., pydoxtools.document.DocumentBag]</p> <p>supports pipelines : *,,,,"},{"location":"documentbag/#e","title":"e","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('e')\n# or\n&lt;DocumentBag&gt;.e\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,,"},{"location":"documentbag/#stats","title":"stats","text":"<p>gather a number of statistics from documents as a pandas dataframe</p> <p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('stats')\n# or\n&lt;DocumentBag&gt;.stats\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,,"},{"location":"documentbag/#vectorizer","title":"vectorizer","text":"<p>vectorizes a query, using the document configuration of the Documentbag to determine which model to use.</p> <p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('vectorizer')\n# or\n&lt;DocumentBag&gt;.vectorizer\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,,"},{"location":"documentbag/#add_to_chroma","title":"add_to_chroma","text":"<p>in order to build an index in chrome db we need a key, text, embeddings and a key. Those come from a daskbag with dictionaries with those keys. pydoxtools will return two functions which will - create the index- query the index</p> <p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('add_to_chroma')\n# or\n&lt;DocumentBag&gt;.add_to_chroma\n</code></pre> <p>return type : </p> <p>supports pipelines : *,,,,"},{"location":"documentbag/#docs","title":"docs","text":"<p>create a bag with one document for each file that was foundFrom this point we can hand off the logic to str(Bag) pipeline.</p> <p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('docs')\n# or\n&lt;DocumentBag&gt;.docs\n</code></pre> <p>return type :  <p>supports pipelines : ,,,"},{"location":"documentbag/#take","title":"take","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('take')\n# or\n&lt;DocumentBag&gt;.take\n</code></pre> <p>return type : </p> <p>supports pipelines : ,,,"},{"location":"documentbag/#compute","title":"compute","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('compute')\n# or\n&lt;DocumentBag&gt;.compute\n</code></pre> <p>return type : </p> <p>supports pipelines : ,,,"},{"location":"documentbag/#sql","title":"sql","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('sql')\n# or\n&lt;DocumentBag&gt;.sql\n</code></pre> <p>return type : </p> <p>supports pipelines :"},{"location":"documentbag/#connection_string","title":"connection_string","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('connection_string')\n# or\n&lt;DocumentBag&gt;.connection_string\n</code></pre> <p>return type : </p> <p>supports pipelines :"},{"location":"documentbag/#index_column","title":"index_column","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('index_column')\n# or\n&lt;DocumentBag&gt;.index_column\n</code></pre> <p>return type : </p> <p>supports pipelines :"},{"location":"documentbag/#bytes_per_chunk","title":"bytes_per_chunk","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('bytes_per_chunk')\n# or\n&lt;DocumentBag&gt;.bytes_per_chunk\n</code></pre> <p>return type : </p> <p>supports pipelines :"},{"location":"documentbag/#dataframe","title":"dataframe","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('dataframe')\n# or\n&lt;DocumentBag&gt;.dataframe\n</code></pre> <p>return type :  <p>supports pipelines :"},{"location":"documentbag/#bag","title":"bag","text":"<p>create a dask bag with all the filepaths in it</p> <p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('bag')\n# or\n&lt;DocumentBag&gt;.bag\n</code></pre> <p>return type : </p> <p>supports pipelines : ,,"},{"location":"documentbag/#root_path","title":"root_path","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('root_path')\n# or\n&lt;DocumentBag&gt;.root_path\n</code></pre> <p>return type : </p> <p>supports pipelines : ,"},{"location":"documentbag/#paths","title":"paths","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('paths')\n# or\n&lt;DocumentBag&gt;.paths\n</code></pre> <p>return type : typing.Callable</p> <p>supports pipelines : ,"},{"location":"documentbag/#file_path_list","title":"file_path_list","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('file_path_list')\n# or\n&lt;DocumentBag&gt;.file_path_list\n</code></pre> <p>return type :  <p>supports pipelines : ,"},{"location":"documentbag/#dir_list","title":"dir_list","text":"<p>Can be called using:</p> <pre><code>&lt;DocumentBag&gt;.x('dir_list')\n# or\n&lt;DocumentBag&gt;.dir_list\n</code></pre> <p>return type :  <p>supports pipelines : ,"},{"location":"examples/","title":"Examples","text":"<p>TODO: add examples</p> <ul> <li>SQL queries</li> <li>automated blog writing</li> <li>table extraction</li> <li>directory index</li> <li>Pandas-style-NLP</li> </ul>"},{"location":"readme_cp/","title":"\ud83d\ude80 pydoxtools (Python Library) \ud83d\ude80","text":"<p>(WIP) Documentation</p> <p>Pydoxtools is a library that provides a sophisticated interface for reading and writing documents, designed to work with AI models such as GPT, Alpaca, and Huggingface. It offers functionalities such as:</p> <ul> <li>Pipeline management</li> <li>Integration with AI (LLMs and more) models</li> <li>low-resource (PDF) table extraction without configuration and expensive   layout detection algorithms!</li> <li>Document analysis and question-answering</li> <li>Support for most of todays document formats</li> <li>Vector index Creation</li> <li>Entity, address identification and more</li> <li>List and keyword extraction</li> <li>Data normalization, translation, and cleaning</li> </ul> <p>The library allows for the creation of complex extraction pipelines for batch-processing of documents by defining them as a lazily-executed graph.</p>"},{"location":"readme_cp/#installation","title":"Installation","text":""},{"location":"readme_cp/#installing-from-github","title":"Installing from GitHub","text":"<p>While pydoxtools can already be installed through pip, due to the many updates coming in right now, it is currently recommended to use the latest version from GitHub as follows:</p> <pre><code>pip install -U \"pydoxtools[etl,inference] @ git+https://github.com/xyntopia/pydoxtools.git\"\n</code></pre>"},{"location":"readme_cp/#installing-from-pypi","title":"Installing from PyPI","text":"<p>Pydoxtools can also be installed through pip, which will become the recommended method once it becomes more stable:</p> <pre><code>pip install -U pydoxtools[etl,inference]\n</code></pre> <p>For loading additional file formats (docx, odt, epub) and images, check out the additional &gt; Installation Options &lt;.</p>"},{"location":"readme_cp/#teaser","title":"Teaser","text":"<p>Experience a new level of convenience and efficiency in handling documents with Pydoxtools, and reimagine your data extraction pipelines! \ud83c\udfa9\u2728\ud83d\udcc4.</p> <p>In this teaser, we'll demonstrate how to create a document, extract tables, and ask questions using AI models:</p> <pre><code>import pydoxtools as pdx\n\n# Create a document from various sources: file, string, bytestring, file-like object, or URL\ndoc = pdx.Document(\"https://www.raspberrypi.org/app/uploads/2012/12/quick-start-guide-v1.1.pdf\")\n\n# List available extraction functions\nprint(doc.x_funcs)\n\n# Extract tables from the PDF as a pandas DataFrame\nprint(doc.tables_df)\n\n# Ask a question about the documents using a local Q&amp;A model\nprint(doc.answers([\"how much ram does it have?\"]))\n# Or only ask about the documents tables (or any other extracted information):\nprint(doc.answers([\"how much ram does it have?\"], \"tables\"))\n\n# To use ChatGPT for question-answering, set the API key as an environment variable:\n# OPENAI_API_KEY=\"sk ....\"\n# Then, ask questions about the document using ChatGPT\nprint(doc.chat_answers([\"What is the target group of this document?\"])[0].content)\nprint(doc.chat_answers([\"Answer if a 5-year old would be able to follow these instructions?\"])[0].content)\n</code></pre> <p>With Pydoxtools, you can easily access and process your documents, perform various extractions, and utilize AI models for more advanced analysis.</p>"},{"location":"readme_cp/#some-features-in-more-detail","title":"Some Features in More Detail","text":""},{"location":"readme_cp/#large-pipelines","title":"Large Pipelines","text":"<p>Pydoxtools' main feature is the ability to mix LLMs and other AI models in large, composable, and customizable pipelines. Using pipelines comes with the slight disadvantage that it can be more challenging to add type hints to the code. However, using pipelines decouples all parts of your code, allowing all operators to work independently. This makes it easy to run the pipeline in a distributed setting for big data and enables easy, lazy evaluation. Additionally, mixing different LLM logics together becomes much easier.</p> <p>Check out how Pydoxtools' <code>Document</code> class mixes pipelines for each individual file type:</p> <ul> <li>Every node in an ellipse can be called as an attribute of the document-analysis pipeline.</li> <li>Every execution path is lazily executed throughout the entire graph.</li> <li>Every node is cached by default (but can be turned off).</li> <li>Every piece of this pipeline can be replaced by a customized version.</li> </ul> <p>As an example, consider this pipeline for *.png images from the repository, which includes OCR, keyword extraction, vectorization, and more:</p> <p></p> <p>Pipelines can be mixed, partially overwritten, and extended, giving you a lot of possibilities to extend and adapt the functionality for your specific use case.</p> <p>To learn more about Pydoxtools' large pipelines feature, please refer to the documentation.</p>"},{"location":"readme_cp/#pipeline-configuration","title":"Pipeline Configuration","text":"<p>Pipelines can be configured. For example the local model used for question answering can be selected like this:</p> <pre><code>doc = Document(fobj=\"./data/PFR-PR23_BAT-110__V1.00_.pdf\"))\n        .config(qam_model_id='bert-large-uncased-whole-word-masking-finetuned-squad')\n</code></pre> <p>where \"qam_model_id\" can be any model from huggingface for question answering.</p> <pre><code>TODO: document how to configure a pipeline\n</code></pre>"},{"location":"readme_cp/#pdf-table-extraction-algorithms","title":"PDF Table Extraction Algorithms","text":"<p>The library features its own sophisticated Table extraction algorithm which is benchmarked against a large pdf table dataset. In contrast to how most \"classical\" table extraction algorithms work, it doesn't require:</p> <ul> <li>extensive configuration</li> <li>no expensive deep neural networks for table area recognition which need a GPU and   a lot of memory/CPU requirements</li> </ul> <p>This makes it possible to run analysis on PDF files with pydoxtools on CPU with very limited resources!</p>"},{"location":"readme_cp/#todo-describe-more-of-the-features-here","title":"TODO: Describe more of the features here...","text":""},{"location":"readme_cp/#use-cases","title":"Use Cases","text":"<ul> <li>analyze documents using any model from huggingface...</li> <li>analyze documents using a custom model</li> <li>download a pdf from URL</li> <li>generate document keywords</li> <li>extract tables</li> <li>download document from URL \"manually\" and then feed to document</li> <li>extract addresses</li> <li>extract addresses and use this information for the qam</li> <li>ingest documents into a vector db</li> </ul>"},{"location":"readme_cp/#installation-options","title":"Installation Options","text":""},{"location":"readme_cp/#supporting-docx-odt-epub","title":"Supporting .docx, .odt, *.epub","text":"<p>In order to be able to load docx, odt and rtf files, you have to install pandoc. Right now, the python pandoc library does not work with pandoc version &gt; 3.0.0. It is therefore recommended to install a version from here for your OS:</p> <p>https://github.com/jgm/pandoc/releases/tag/2.19.2</p>"},{"location":"readme_cp/#image-ocr-support","title":"Image OCR Support","text":"<p>Pydoxtools can automatically analyze images as well, makin use of OCR. In order to be able to use this, install tesseract on your system:</p> <p>Under linux this looks like the following:</p> <pre><code>apt-get update &amp;&amp; tesseract-ocr\n# install tesseract languages \n# Display a list of all Tesseract language packs:\n#   apt-cache search tesseract-ocr\n# install all languages:\n# sudo apt install tesseract-ocr-*\n# install only german, french, english, spanish language packs\n# sudo apt install tesseract-ocr-deu tesseract-ocr-fra tesseract-ocr-eng tesseract-ocr-spa\n</code></pre>"},{"location":"readme_cp/#development","title":"Development","text":"<p>--&gt; see </p>"},{"location":"readme_cp/#license","title":"License","text":"<p>This project is licensed under the terms of MIT license.</p> <p>You can check the compatibility using the following tool in a venv environment in a production setting:</p> <pre><code>pip install pip-licenses\npip-licenses | grep -Ev 'MIT License|BSD License|Apache Software License|Python Software Foundation License|Apache 2.0|MIT|Apache License 2.0|hnswlib|Pillow|new BSD|BSD'\n</code></pre>"},{"location":"readme_cp/#dependencies","title":"Dependencies","text":"<p>Here is a list of Libraries, that this project is based on:</p> <p>list</p>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#pydoxtools.document_base.Pipeline","title":"<code>Pipeline</code>","text":"<p>Base class for all document classes in pydoxtools, defining a common pipeline interface and establishing a basic pipeline schema that derived classes can override.</p> <p>The MetaPipelineClassConfiguration acts as a compiler to resolve the pipeline hierarchy, allowing pipelines to inherit, mix, extend, or partially overwrite each other. Each key in the _pipelines dictionary represents a different pipeline version.</p> <p>The pydoxtools.Document class leverages this functionality to build separate pipelines for different file types, as the information processing requirements differ significantly between file types.</p> <p>Attributes:</p> Name Type Description <code>_operators</code> <code>dict[str, list[pydoxtools.operators_base.Operator]]</code> <p>Stores the definition of the pipeline graph, a collection of connected operators/functions that process data from a document.</p> <code>_pipelines</code> <code>dict[str, dict[str, pydoxtools.operators_base.Operator]]</code> <p>Provides access to all operator functions by their \"out-key\" which was defined in _operators.</p> Todo <ul> <li>Use pandera (https://github.com/unionai-oss/pandera) to validate dataframes   exchanged between extractors &amp; loaders   (https://pandera.readthedocs.io/en/stable/pydantic_integration.html)</li> </ul>"},{"location":"reference/#pydoxtools.document_base.Pipeline.configuration","title":"<code>configuration</code>  <code>property</code>","text":"<p>Returns a dictionary of all configuration objects for the current pipeline.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the names and values of all configuration objects   for the current pipeline.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.pipeline_chooser","title":"<code>pipeline_chooser: str</code>  <code>property</code>","text":"<p>Must be implemented by derived classes to decide which pipeline they should use.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.uuid","title":"<code>uuid</code>  <code>property</code> <code>cached</code>","text":"<p>Retrieves a universally unique identifier (UUID) for the instance.</p> <p>This method generates a new UUID for the instance using Python's <code>uuid.uuid4()</code> function. The UUID is then cached as a property, ensuring that the same UUID is returned for subsequent accesses.</p> <p>Returns:</p> Type Description <p>uuid.UUID: A unique identifier for the instance.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.x_funcs","title":"<code>x_funcs: dict[str, Operator]</code>  <code>property</code> <code>cached</code>","text":"<p>get all operators/pipeline nodes and their property names for this specific file type/pipeline</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.__getattr__","title":"<code>__getattr__(extract_name)</code>","text":"<p>Retrieves an extractor result by directly accessing it as an attribute.</p> <p>This method is automatically called for attribute names that aren't defined on class level, allowing for a convenient way to access pipeline operator outputs without needing to call the 'x' method.</p> Example <p>document.addresses instead of document.x('addresses')</p> <p>Parameters:</p> Name Type Description Default <code>extract_name</code> <code>str</code> <p>The name of the extractor result to be accessed.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result of the extractor after processing the document.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.__getitem__","title":"<code>__getitem__(extract_name)</code>","text":"<p>Retrieves an extractor result by directly accessing it as an attribute.</p> <p>This method is automatically called for attribute names that aren't defined on class level, allowing for a convenient way to access pipeline operator outputs without needing to call the 'x' method.</p> Example <p>document[\"addresses\"] instead of document.x('addresses')</p> <p>Parameters:</p> Name Type Description Default <code>extract_name</code> <code>str</code> <p>The name of the extractor result to be accessed.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result of the extractor after processing the document.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.__getstate__","title":"<code>__getstate__()</code>","text":"<p>return necessary variables for pickling, ensuring that we leave out everything that can potentiall have some sort of a lambda function in it...</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the Pipeline instance with cache-related attributes.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.__repr__","title":"<code>__repr__()</code>","text":"<p>Returns:</p> Name Type Description <code>str</code> <p>A string representation of the instance.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>we need to restore _x_func_cache for pickling to work...</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.config","title":"<code>config(**configuration)</code>","text":"<p>Set configuration parameters for a pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>**configuration</code> <code>Any</code> <p>A dictionary of key-value pairs representing the configuration settings for the pipeline. Each key is a string representing the name of the configuration setting, and the value is the corresponding value to be set.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>self</code> <code>Pipeline</code> <p>A reference to the current pipeline instance, allowing for method chaining.</p> Example <p>pipeline = Pipeline() pipeline.config(param1=value1, param2=value2)</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.gather_arguments","title":"<code>gather_arguments(**kwargs)</code>","text":"<p>Gathers arguments from the pipeline and class, and maps them to the provided keys of kwargs.</p> <p>This method retrieves all required input parameters from _in_mapping, which was declared with \"pipe\". It first checks if the parameter is available as an extractor. If so, it calls the function to get the value. Otherwise, it gets the \"native\" member-variables or other functions if an extractor with that name is not found.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>A dictionary containing the keys to be mapped to the corresponding values.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the mapped keys and their corresponding values.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.get_configuration_names","title":"<code>get_configuration_names(pipeline)</code>  <code>classmethod</code> <code>cached</code>","text":"<p>Returns a list of names of all configuration objects for a given pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>pipeline</code> <code>str</code> <p>The name of the pipeline to retrieve configuration objects from.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list[str]</code> <p>A list of strings containing the names of all configuration objects for the   given pipeline.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.markdown_docs","title":"<code>markdown_docs()</code>  <code>classmethod</code>","text":"<p>Returns a formatted string containing the documentation for each pipeline operation in the class.</p> <p>This class method iterates through the pipeline operations, collects information about their output types and supported pipelines, and formats the documentation accordingly.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>A formatted string containing the documentation for each pipeline operation, including  operation name, usage, return type, and supported pipelines.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.non_interactive_pipeline","title":"<code>non_interactive_pipeline()</code>","text":"<p>return all non-interactive extractors/pipeline nodes</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.pipeline_docs","title":"<code>pipeline_docs(pipeline_type=None)</code>  <code>classmethod</code>","text":"<p>Aggregates the pipeline operations and their corresponding types and metadata.</p> <p>This method iterates through all the pipelines registered in the class, and gathers information about each operation, such as the pipeline types it appears in, the return type of the operation, and the operation's docstring.</p> <p>Returns:</p> Name Type Description <code>output_infos</code> <code>Dict[str, Dict[str, Union[Set, str]]]</code> <p>The aggregated information about pipeline operations, with operation keys as the top-level keys, and metadata such as pipeline types, output types, and descriptions as nested dictionaries.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.pipeline_graph","title":"<code>pipeline_graph(image_path=None, document_logic_id='*')</code>  <code>classmethod</code>","text":"<p>Generates a visualization of the defined pipelines and optionally saves it as an image.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str | pathlib.Path</code> <p>File path for the generated image. If provided, the                                        generated graph will be saved as an image.</p> <code>None</code> <code>document_logic_id</code> <code>str</code> <p>The document logic ID for which the pipeline graph should                                be generated. Defaults to \"current\".</p> <code>'*'</code> <p>Returns:</p> Name Type Description <code>AGraph</code> <p>A PyGraphviz AGraph object representing the pipeline graph. This object can be     visualized or manipulated using PyGraphviz functions.</p> Notes <p>This method requires the NetworkX and PyGraphviz libraries to be installed.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.pre_cache","title":"<code>pre_cache()</code>","text":"<p>Pre-caches the results of all extractors that have caching enabled.</p> <p>This method iterates through the defined extractors and calls each one with caching enabled, storing the results for faster access in future calls.</p> <p>Returns:</p> Name Type Description <code>self</code> <p>The instance of the class, allowing for method chaining.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.run_pipeline","title":"<code>run_pipeline(exclude=None)</code>","text":"<p>Runs all extractors defined in the pipeline for testing or pre-caching purposes.</p> <p>!!IMPORTANT!!!  This function should normally not be used as the pipeline is lazily executed anyway.</p> <p>This method iterates through the defined extractors and calls each one, ensuring that the extractor logic is functioning correctly and caching the results if required.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.run_pipeline_fast","title":"<code>run_pipeline_fast()</code>","text":"<p>run pipeline, but exclude long-running calculations</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.set_disk_cache_settings","title":"<code>set_disk_cache_settings(enable, ttl=3600 * 24 * 7)</code>","text":"<p>Sets disk cache settings</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.to_dict","title":"<code>to_dict(*args, **kwargs)</code>","text":"<p>Returns a dictionary that accumulates the properties given in args or with a mapping in *kwargs.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>str</code> <p>A variable number of strings, each representing a property name.</p> <code>()</code> <code>**kwargs</code> <code>dict</code> <p>A dictionary mapping property names (values) to custom keys (keys) for the              returned dictionary.</p> <code>{}</code> Note <p>This function currently only supports properties that do not require any arguments, such as \"full_text\". Properties like \"answers\" that return a function requiring arguments cannot be used with this function.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary with the accumulated properties and their values, using either the   property names or custom keys as specified in the input arguments.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.to_json","title":"<code>to_json(*args, **kwargs)</code>","text":"<p>Returns a dictionary that accumulates the properties given in args or with a mapping in *kwargs, and dumps the output as JSON.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>str</code> <p>A variable number of strings, each representing a property name.</p> <code>()</code> <code>**kwargs</code> <code>dict</code> <p>A dictionary mapping property names (values) to custom keys (keys) for the              returned dictionary.</p> <code>{}</code> Note <p>This function currently only supports properties that do not require any arguments, such as \"full_text\". Properties like \"answers\" that return a function requiring arguments cannot be used with this function.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>A JSON-formatted string representing the accumulated properties and their values, using  either the property names or custom keys as specified in the input arguments.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.to_yaml","title":"<code>to_yaml(*args, **kwargs)</code>","text":"<p>Returns a dictionary that accumulates the properties given in args or with a mapping in *kwargs, and dumps the output as YAML.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>str</code> <p>A variable number of strings, each representing a property name.</p> <code>()</code> <code>**kwargs</code> <code>dict</code> <p>A dictionary mapping property names (values) to custom keys (keys) for the              returned dictionary.</p> <code>{}</code> Note <p>This function currently only supports properties that do not require any arguments, such as \"full_text\". Properties like \"answers\" that return a function requiring arguments cannot be used with this function.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>A YAML-formatted string representing the accumulated properties and their values, using  either the property names or custom keys as specified in the input arguments.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.x","title":"<code>x(operator_name)</code>","text":"<p>Calls an extractor from the defined pipeline and returns the result.</p> <p>Parameters:</p> Name Type Description Default <code>operator_name</code> <code>str</code> <p>The name of the extractor to be called.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result of the extractor after processing the document.</p> <p>Raises:</p> Type Description <code>operators.OperatorException</code> <p>If an error occurs while executing the extractor.</p> Notes <p>The extractor's parameters can be overridden using args and *kwargs.</p>"},{"location":"reference/#pydoxtools.document_base.Pipeline.x_all","title":"<code>x_all()</code>","text":"<p>Retrieves the results of all extractors defined in the pipeline.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the results of all extractors, with keys as the extractor   names and values as the corresponding results.</p>"},{"location":"reference/#pydoxtools.operators","title":"<code>pydoxtools.operators</code>","text":"<p>This module simply gathers all operators from across the board to make them easier to access.</p>"}]}