{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "synchronize your pydoxtools directory:\n",
        "\n",
        "- rclone sync pydoxtools/ xyntopia_gdrive:/pydoxtools -P --size-only --fast-list"
      ],
      "metadata": {
        "id": "gfrmJvSONmBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "#import os\n",
        "#assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "metadata": {
        "id": "LzWIvGjIWeOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch\n",
        "#import torch_xla\n",
        "#import torch_xla.core.xla_model as xm\n",
        "#\n",
        "#t = torch.randn(2, 2, device=xm.xla_device())\n",
        "#print(t.device)\n",
        "#print(t)"
      ],
      "metadata": {
        "id": "a1uyZN6_WHiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "OfHZ2kprTjuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setup pydoxtools code access, data & gdrive"
      ],
      "metadata": {
        "id": "IpfYEVIhZ6he"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dgIb3slMjOs"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PDX_DIR=\"/content/pydoxtools\""
      ],
      "metadata": {
        "id": "roTdjgU1_DD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pytorch-lightning faker evaluate transformers datasets accelerate nvidia-ml-py3 sklearn"
      ],
      "metadata": {
        "id": "hrwTZAVnguJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/gdrive/My Drive/pydoxtools/pydoxtools\"\n",
        "!rm -r $PDX_DIR\n",
        "!cp -r \"/content/gdrive/My Drive/pydoxtools/pydoxtools\" $PDX_DIR"
      ],
      "metadata": {
        "id": "sljq7wNmMpDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main issue when using google colab for our training is, that we only have python version 3.9 available, while pydoxtools currently needs 3.10 to function.and\n",
        "\n",
        "because of this we are trying to only use the relevant parts of the library which is mainly the data generation part which is used for\n",
        "the training."
      ],
      "metadata": {
        "id": "TfzfmVfq1jVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm $PDX_DIR/__init__.py\n",
        "!touch $PDX_DIR/__init__.py\n",
        "!pwd"
      ],
      "metadata": {
        "id": "M1mr_xOn2fEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "finally...  run pydoxtools"
      ],
      "metadata": {
        "id": "_TRbPGU3RaTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure we set the environment variable before loading pydoxtools for the first time\n",
        "%env TRAINING_DATA_DIR=/content/gdrive/MyDrive/pydoxtools/training_data\n",
        "from pydoxtools import random_data_generators, training"
      ],
      "metadata": {
        "id": "HbAWiShuTxHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prepare training"
      ],
      "metadata": {
        "id": "m0ircFG6WaHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bg = random_data_generators.TextBlockGenerator.std_generator()\n",
        "bg.classmap, bg.classmap_inv, bg.num_generators, bg.class_gen, bg.gen_mapping, bg.weights"
      ],
      "metadata": {
        "id": "ghNUEyG04OB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bg.gen_mapping"
      ],
      "metadata": {
        "id": "EpjrS5FKZ2bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bg.single(1000, convert_labels=True)"
      ],
      "metadata": {
        "id": "6RSpKOEaqh5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df,y = training.load_labeled_text_block_data(classmap=bg.classmap_inv)\n",
        "df[\"label\"]=y\n",
        "df = df.rename(columns={\"txt\":\"text\"}).drop(columns=\"filename\")"
      ],
      "metadata": {
        "id": "Q4OnANpHZiKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "72JsDSeaci9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.label.unique()"
      ],
      "metadata": {
        "id": "BpEZgTBrm9HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, Features, Value, ClassLabel\n",
        "import random\n",
        "\n",
        "dataset_size=200000\n",
        "\n",
        "# generate datasets for finetuning\n",
        "def my_gen():\n",
        "    seed=random.randint(0,10000000)\n",
        "    for i in range(1, dataset_size):\n",
        "        text, label = bg.single(i+seed, convert_labels=True)\n",
        "        yield {\"label\": label, \"text\":text}\n",
        "\n",
        "class_names = [\"address\", \"unknown\"]\n",
        "features = Features({'text': Value('string'), 'label': ClassLabel(names=class_names)})\n",
        "\n",
        "dataset = Dataset.from_generator(my_gen, features=features)\n",
        "dataset.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "AbR78dTJ3tFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = Dataset.from_pandas(df,features=features) # this will already convert our labels!\n",
        "val_dataset.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "rxKppLhadEKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, val_dataset"
      ],
      "metadata": {
        "id": "PrHf7iWiRx5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.features"
      ],
      "metadata": {
        "id": "HARgcFnOkE9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "# model_name=\"bert-base-cased\""
      ],
      "metadata": {
        "id": "bgsenNBIh67I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "def tokenize_function(batch):\n",
        "    tokenized_batch = tokenizer(batch['text'], padding=\"max_length\", truncation=True)\n",
        "    #print(batch[\"label\"])\n",
        "    #tokenized_batch[\"labels\"] = [bg.classmap_inv[label] for label in batch[\"label\"]]\n",
        "    return tokenized_batch"
      ],
      "metadata": {
        "id": "eQ8f2fOXRDV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset.map(tokenize_function, batched=True)\n",
        "validation_dataset = val_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "37qmK5At5cjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select smaller subdataset\n",
        "#train_dataset = tokenized_datasets.shuffle(seed=42).select(range(1000))\n",
        "#eval_dataset = tokenized_datasets.shuffle(seed=42).select(range(1000))"
      ],
      "metadata": {
        "id": "phUX3LpERmYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "YTsm0q7EqxLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = AutoModelForSequenceClassification.from_pretrained(, num_labels=2).to(\"cuda\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(\"cuda\")"
      ],
      "metadata": {
        "id": "56kmpOwDrABc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments"
      ],
      "metadata": {
        "id": "EvoSpUGZta9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "HQm0-7u_tmKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_metric = evaluate.load(\"f1\")\n",
        "acc = evaluate.load(\"accuracy\")\n",
        "rec = evaluate.load(\"recall\")\n",
        "prec = evaluate.load(\"precision\")"
      ],
      "metadata": {
        "id": "dyUgKsiEttmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
      ],
      "metadata": {
        "id": "2Jdo6tr6twOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        **f1_metric.compute(predictions=predictions, references=labels),\n",
        "        **acc.compute(predictions=predictions, references=labels),\n",
        "        **rec.compute(predictions=predictions, references=labels),\n",
        "        **prec.compute(predictions=predictions, references=labels)\n",
        "    }\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    metrics = classification_report(predictions, labels, output_dict=True)\n",
        "    label=str(bg.classmap_inv['address'])\n",
        "    return {\n",
        "        \"address.f1\":metrics[label][\"f1-score\"],\n",
        "        \"accuracy\":metrics[\"accuracy\"],\n",
        "        \"address.precision\":metrics[label][\"precision\"],\n",
        "        \"address.recall\":metrics[label][\"recall\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "79GZRfIIumLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!nvidia-smi"
      ],
      "metadata": {
        "id": "XpEFOn2waQ8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## run actual training"
      ],
      "metadata": {
        "id": "WPmDvctuYpsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#metric"
      ],
      "metadata": {
        "id": "HgSjn496WWmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_args = {\n",
        "    \"output_dir\": \"/content/gdrive/MyDrive/models/txtblock\",\n",
        "    \"evaluation_strategy\": \"steps\",\n",
        "    \"num_train_epochs\": 10,\n",
        "    \"log_level\": \"info\",\n",
        "    #\"label_names\": \"label\",\n",
        "    \"logging_strategy\": \"steps\",\n",
        "    \"logging_steps\": 200, \n",
        "    \"save_strategy\":\"steps\",\n",
        "    \"save_steps\": 200,\n",
        "    \"report_to\": \"none\",\n",
        "    \"metric_for_best_model\":\"address.f1\"\n",
        "}"
      ],
      "metadata": {
        "id": "fzzadAstajcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=44,\n",
        "    #gradient_accumulation_steps=4,\n",
        "    #gradient_checkpointing=True,\n",
        "    **default_args)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "#result = trainer.train()\n",
        "#print_summary(result)"
      ],
      "metadata": {
        "id": "9P5rbXIPuuWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "YDR8f0pLicyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "64eATEegt2gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "oliXF-iHbQAs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}