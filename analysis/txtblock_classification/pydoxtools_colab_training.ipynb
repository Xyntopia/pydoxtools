{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "synchronize your pydoxtools directory:\n",
        "\n",
        "- rclone sync pydoxtools/ xyntopia_gdrive:/pydoxtools -P --size-only --fast-list"
      ],
      "metadata": {
        "id": "gfrmJvSONmBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "#assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "metadata": {
        "id": "LzWIvGjIWeOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch\n",
        "#import torch_xla\n",
        "#import torch_xla.core.xla_model as xm\n",
        "#\n",
        "#t = torch.randn(2, 2, device=xm.xla_device())\n",
        "#print(t.device)\n",
        "#print(t)"
      ],
      "metadata": {
        "id": "a1uyZN6_WHiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "OfHZ2kprTjuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setup pydoxtools code access, data & gdrive"
      ],
      "metadata": {
        "id": "IpfYEVIhZ6he"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dgIb3slMjOs"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PDX_DIR=\"/content/pydoxtools\""
      ],
      "metadata": {
        "id": "roTdjgU1_DD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env TRAINING_DATA_DIR=/content/gdrive/MyDrive/pydoxtools/training_data"
      ],
      "metadata": {
        "id": "Rt1PNucckNHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker evaluate transformers datasets accelerate nvidia-ml-py3"
      ],
      "metadata": {
        "id": "hrwTZAVnguJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/gdrive/My Drive/pydoxtools/pydoxtools\"\n",
        "!rm -r $PDX_DIR\n",
        "!cp -r \"/content/gdrive/My Drive/pydoxtools/pydoxtools\" $PDX_DIR"
      ],
      "metadata": {
        "id": "sljq7wNmMpDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main issue when using google colab for our training is, that we only have python version 3.9 available, while pydoxtools currently needs 3.10 to function.and\n",
        "\n",
        "because of this we are trying to only use the relevant parts of the library which is mainly the data generation part which is used for\n",
        "the training."
      ],
      "metadata": {
        "id": "TfzfmVfq1jVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm $PDX_DIR/__init__.py\n",
        "!touch $PDX_DIR/__init__.py\n",
        "!pwd"
      ],
      "metadata": {
        "id": "M1mr_xOn2fEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "finally...  run pydoxtools"
      ],
      "metadata": {
        "id": "_TRbPGU3RaTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydoxtools import random_data_generators"
      ],
      "metadata": {
        "id": "HbAWiShuTxHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prepare training"
      ],
      "metadata": {
        "id": "m0ircFG6WaHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bg = random_data_generators.TextBlockGenerator.std_generator()\n",
        "bg.classmap, bg.classmap_inv, bg.num_generators, bg.class_gen, bg.gen_mapping, bg.weights"
      ],
      "metadata": {
        "id": "ghNUEyG04OB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bg[10]"
      ],
      "metadata": {
        "id": "PqGFVCZrwjR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "dataset_size=10000\n",
        "\n",
        "# generate datasets for finetuning\n",
        "def my_gen():\n",
        "    bgi = bg.__iter__()\n",
        "    for i in range(1, dataset_size):\n",
        "        text, label = next(bgi)\n",
        "        yield {\"label\": label, \"text\":text}\n",
        "\n",
        "\n",
        "dataset = Dataset.from_generator(my_gen)\n",
        "dataset.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "AbR78dTJ3tFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "PrHf7iWiRx5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "# model_name=\"bert-base-cased\""
      ],
      "metadata": {
        "id": "bgsenNBIh67I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "eQ8f2fOXRDV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_datasets.shuffle(seed=42).select(range(1000))\n",
        "eval_dataset = tokenized_datasets.shuffle(seed=42).select(range(1000))"
      ],
      "metadata": {
        "id": "phUX3LpERmYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "YTsm0q7EqxLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = AutoModelForSequenceClassification.from_pretrained(, num_labels=2).to(\"cuda\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(\"cuda\")"
      ],
      "metadata": {
        "id": "56kmpOwDrABc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments"
      ],
      "metadata": {
        "id": "EvoSpUGZta9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "HQm0-7u_tmKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"accuracy\")"
      ],
      "metadata": {
        "id": "dyUgKsiEttmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
      ],
      "metadata": {
        "id": "2Jdo6tr6twOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "79GZRfIIumLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setup hardware"
      ],
      "metadata": {
        "id": "153o4AhWXNB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pynvml import *\n",
        "\n",
        "\n",
        "def print_gpu_utilization():\n",
        "    nvmlInit()\n",
        "    handle = nvmlDeviceGetHandleByIndex(0)\n",
        "    info = nvmlDeviceGetMemoryInfo(handle)\n",
        "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
        "\n",
        "\n",
        "def print_summary(result):\n",
        "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
        "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
        "    print_gpu_utilization()"
      ],
      "metadata": {
        "id": "-EwEPGAkXQdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_gpu_utilization()"
      ],
      "metadata": {
        "id": "arnb7zerZhu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!nvidia-smi"
      ],
      "metadata": {
        "id": "XpEFOn2waQ8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## run actual training"
      ],
      "metadata": {
        "id": "WPmDvctuYpsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_args = {\n",
        "    \"output_dir\": \"test_trainer\",\n",
        "    \"evaluation_strategy\": \"steps\",\n",
        "    \"num_train_epochs\": 10,\n",
        "    \"log_level\": \"error\",\n",
        "    \"report_to\": \"none\",\n",
        "}"
      ],
      "metadata": {
        "id": "fzzadAstajcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer, logging\n",
        "\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=8,\n",
        "    #gradient_accumulation_steps=4,\n",
        "    #gradient_checkpointing=True,\n",
        "    **default_args)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=train_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "#result = trainer.train()\n",
        "#print_summary(result)"
      ],
      "metadata": {
        "id": "9P5rbXIPuuWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainer.train()"
      ],
      "metadata": {
        "id": "YDR8f0pLicyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "oliXF-iHbQAs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}